{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gradio in c:\\users\\marwan shamsan\\anaconda3\\lib\\site-packages (5.14.0)\n",
      "Requirement already satisfied: scikit-image in c:\\users\\marwan shamsan\\anaconda3\\lib\\site-packages (0.22.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\marwan shamsan\\anaconda3\\lib\\site-packages (1.2.2)\n",
      "Collecting cupy\n",
      "  Using cached cupy-13.3.0.tar.gz (3.4 MB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: matplotlib in c:\\users\\marwan shamsan\\anaconda3\\lib\\site-packages (3.8.0)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in c:\\users\\marwan shamsan\\anaconda3\\lib\\site-packages (from gradio) (23.2.1)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in c:\\users\\marwan shamsan\\anaconda3\\lib\\site-packages (from gradio) (4.2.0)\n",
      "Requirement already satisfied: fastapi<1.0,>=0.115.2 in c:\\users\\marwan shamsan\\anaconda3\\lib\\site-packages (from gradio) (0.115.8)\n",
      "Requirement already satisfied: ffmpy in c:\\users\\marwan shamsan\\anaconda3\\lib\\site-packages (from gradio) (0.5.0)\n",
      "Requirement already satisfied: gradio-client==1.7.0 in c:\\users\\marwan shamsan\\anaconda3\\lib\\site-packages (from gradio) (1.7.0)\n",
      "Requirement already satisfied: httpx>=0.24.1 in c:\\users\\marwan shamsan\\anaconda3\\lib\\site-packages (from gradio) (0.28.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.25.1 in c:\\users\\marwan shamsan\\anaconda3\\lib\\site-packages (from gradio) (0.28.1)\n",
      "Requirement already satisfied: jinja2<4.0 in c:\\users\\marwan shamsan\\anaconda3\\lib\\site-packages (from gradio) (3.1.3)\n",
      "Requirement already satisfied: markupsafe~=2.0 in c:\\users\\marwan shamsan\\anaconda3\\lib\\site-packages (from gradio) (2.1.3)\n",
      "Requirement already satisfied: numpy<3.0,>=1.0 in c:\\users\\marwan shamsan\\anaconda3\\lib\\site-packages (from gradio) (1.26.4)\n",
      "Requirement already satisfied: orjson~=3.0 in c:\\users\\marwan shamsan\\anaconda3\\lib\\site-packages (from gradio) (3.10.15)\n",
      "Requirement already satisfied: packaging in c:\\users\\marwan shamsan\\anaconda3\\lib\\site-packages (from gradio) (23.1)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in c:\\users\\marwan shamsan\\anaconda3\\lib\\site-packages (from gradio) (2.1.4)\n",
      "Requirement already satisfied: pillow<12.0,>=8.0 in c:\\users\\marwan shamsan\\anaconda3\\lib\\site-packages (from gradio) (10.2.0)\n",
      "Requirement already satisfied: pydantic>=2.0 in c:\\users\\marwan shamsan\\anaconda3\\lib\\site-packages (from gradio) (2.10.6)\n",
      "Requirement already satisfied: pydub in c:\\users\\marwan shamsan\\anaconda3\\lib\\site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.18 in c:\\users\\marwan shamsan\\anaconda3\\lib\\site-packages (from gradio) (0.0.20)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in c:\\users\\marwan shamsan\\anaconda3\\lib\\site-packages (from gradio) (6.0.1)\n",
      "Requirement already satisfied: ruff>=0.9.3 in c:\\users\\marwan shamsan\\anaconda3\\lib\\site-packages (from gradio) (0.9.4)\n",
      "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in c:\\users\\marwan shamsan\\anaconda3\\lib\\site-packages (from gradio) (0.1.6)\n",
      "Requirement already satisfied: semantic-version~=2.0 in c:\\users\\marwan shamsan\\anaconda3\\lib\\site-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: starlette<1.0,>=0.40.0 in c:\\users\\marwan shamsan\\anaconda3\\lib\\site-packages (from gradio) (0.45.3)\n",
      "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in c:\\users\\marwan shamsan\\anaconda3\\lib\\site-packages (from gradio) (0.13.2)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in c:\\users\\marwan shamsan\\anaconda3\\lib\\site-packages (from gradio) (0.15.1)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in c:\\users\\marwan shamsan\\anaconda3\\lib\\site-packages (from gradio) (4.12.2)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in c:\\users\\marwan shamsan\\anaconda3\\lib\\site-packages (from gradio) (0.34.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\marwan shamsan\\anaconda3\\lib\\site-packages (from gradio-client==1.7.0->gradio) (2023.10.0)\n",
      "Requirement already satisfied: websockets<15.0,>=10.0 in c:\\users\\marwan shamsan\\anaconda3\\lib\\site-packages (from gradio-client==1.7.0->gradio) (14.2)\n",
      "Requirement already satisfied: scipy>=1.8 in c:\\users\\marwan shamsan\\anaconda3\\lib\\site-packages (from scikit-image) (1.11.4)\n",
      "Requirement already satisfied: networkx>=2.8 in c:\\users\\marwan shamsan\\anaconda3\\lib\\site-packages (from scikit-image) (3.1)\n",
      "Requirement already satisfied: imageio>=2.27 in c:\\users\\marwan shamsan\\anaconda3\\lib\\site-packages (from scikit-image) (2.33.1)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in c:\\users\\marwan shamsan\\anaconda3\\lib\\site-packages (from scikit-image) (2023.4.12)\n",
      "Requirement already satisfied: lazy_loader>=0.3 in c:\\users\\marwan shamsan\\anaconda3\\lib\\site-packages (from scikit-image) (0.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\marwan shamsan\\anaconda3\\lib\\site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\marwan shamsan\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: fastrlock>=0.5 in c:\\users\\marwan shamsan\\anaconda3\\lib\\site-packages (from cupy) (0.8.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\marwan shamsan\\anaconda3\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\marwan shamsan\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\marwan shamsan\\anaconda3\\lib\\site-packages (from matplotlib) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\marwan shamsan\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\marwan shamsan\\anaconda3\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\marwan shamsan\\anaconda3\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\marwan shamsan\\anaconda3\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\marwan shamsan\\anaconda3\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (1.3.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\marwan shamsan\\anaconda3\\lib\\site-packages (from httpx>=0.24.1->gradio) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\marwan shamsan\\anaconda3\\lib\\site-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\marwan shamsan\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\marwan shamsan\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.25.1->gradio) (3.13.1)\n",
      "Requirement already satisfied: requests in c:\\users\\marwan shamsan\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.25.1->gradio) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\marwan shamsan\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.25.1->gradio) (4.65.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\marwan shamsan\\anaconda3\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\marwan shamsan\\anaconda3\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2023.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\marwan shamsan\\anaconda3\\lib\\site-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\marwan shamsan\\anaconda3\\lib\\site-packages (from pydantic>=2.0->gradio) (2.27.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\marwan shamsan\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\marwan shamsan\\anaconda3\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\marwan shamsan\\anaconda3\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\marwan shamsan\\anaconda3\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (13.3.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\marwan shamsan\\anaconda3\\lib\\site-packages (from click>=8.0.0->typer<1.0,>=0.12->gradio) (0.4.6)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\users\\marwan shamsan\\anaconda3\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\marwan shamsan\\anaconda3\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.15.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\marwan shamsan\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.25.1->gradio) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\marwan shamsan\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.25.1->gradio) (2.0.7)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\marwan shamsan\\anaconda3\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.0)\n",
      "Building wheels for collected packages: cupy\n",
      "  Building wheel for cupy (setup.py): started\n",
      "  Building wheel for cupy (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for cupy\n",
      "Failed to build cupy\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × python setup.py bdist_wheel did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [59 lines of output]\n",
      "      Generating cache key from header files...\n",
      "      Cache key (1610 files matching C:\\Users\\Marwan Shamsan\\AppData\\Local\\Temp\\pip-install-a444wtr1\\cupy_fd9d91c0a655455596ca8a90198f47dd\\cupy\\_core\\include\\**): 8aad1231f702316b675b9ad296f56a95316298c2\n",
      "      Clearing directory: C:\\Users\\Marwan Shamsan\\AppData\\Local\\Temp\\pip-install-a444wtr1\\cupy_fd9d91c0a655455596ca8a90198f47dd\\cupy\\.data\n",
      "      Looking for NVTX: C:\\Program Files\\NVIDIA Corporation\\Nsight Systems *\\target-windows-x64\\nvtx\n",
      "      Using NVTX at: C:\\Program Files\\NVIDIA Corporation\\Nsight Systems 2024.6.2\\target-windows-x64\\nvtx\n",
      "      \n",
      "      -------- Configuring Module: cuda --------\n",
      "      Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "      **************************************************\n",
      "      *** WARNING: Cannot check compute capability\n",
      "      Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "      **************************************************\n",
      "      \n",
      "      ************************************************************\n",
      "      * CuPy Configuration Summary                               *\n",
      "      ************************************************************\n",
      "      \n",
      "      Build Environment:\n",
      "        Include directories: ['C:\\\\Users\\\\Marwan Shamsan\\\\AppData\\\\Local\\\\Temp\\\\pip-install-a444wtr1\\\\cupy_fd9d91c0a655455596ca8a90198f47dd\\\\cupy/_core/include\\\\cupy/_cccl/libcudacxx', 'C:\\\\Users\\\\Marwan Shamsan\\\\AppData\\\\Local\\\\Temp\\\\pip-install-a444wtr1\\\\cupy_fd9d91c0a655455596ca8a90198f47dd\\\\cupy/_core/include\\\\cupy/_cccl/thrust', 'C:\\\\Users\\\\Marwan Shamsan\\\\AppData\\\\Local\\\\Temp\\\\pip-install-a444wtr1\\\\cupy_fd9d91c0a655455596ca8a90198f47dd\\\\cupy/_core/include\\\\cupy/_cccl/cub', 'C:\\\\Users\\\\Marwan Shamsan\\\\AppData\\\\Local\\\\Temp\\\\pip-install-a444wtr1\\\\cupy_fd9d91c0a655455596ca8a90198f47dd\\\\cupy/_core/include', 'C:\\\\Program Files\\\\NVIDIA GPU Computing Toolkit\\\\CUDA\\\\v12.8\\\\include', 'C:\\\\Program Files\\\\NVIDIA Corporation\\\\Nsight Systems 2024.6.2\\\\target-windows-x64\\\\nvtx\\\\include']\n",
      "        Library directories: ['C:\\\\Program Files\\\\NVIDIA GPU Computing Toolkit\\\\CUDA\\\\v12.8\\\\bin', 'C:\\\\Program Files\\\\NVIDIA GPU Computing Toolkit\\\\CUDA\\\\v12.8\\\\lib\\\\x64']\n",
      "        nvcc command       : ['C:\\\\Program Files\\\\NVIDIA GPU Computing Toolkit\\\\CUDA\\\\v12.8\\\\bin/nvcc.exe']\n",
      "        hipcc command      : (not found)\n",
      "      \n",
      "      Environment Variables:\n",
      "        CFLAGS          : (none)\n",
      "        LDFLAGS         : (none)\n",
      "        LIBRARY_PATH    : (none)\n",
      "        CUDA_PATH       : C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.8\n",
      "        NVCC            : (none)\n",
      "        HIPCC           : (none)\n",
      "        ROCM_HOME       : (none)\n",
      "      \n",
      "      Modules:\n",
      "        cuda      : No\n",
      "          -> Include files not found: ['cublas_v2.h', 'cuda.h', 'cuda_profiler_api.h', 'cuda_runtime.h', 'cufft.h', 'curand.h', 'cusparse.h']\n",
      "          -> Check your CFLAGS environment variable.\n",
      "      \n",
      "      ERROR: CUDA could not be found on your system.\n",
      "      \n",
      "      HINT: You are trying to build CuPy from source, which is NOT recommended for general use.\n",
      "            Please consider using binary packages instead.\n",
      "      \n",
      "      Please refer to the Installation Guide for details:\n",
      "      https://docs.cupy.dev/en/stable/install.html\n",
      "      \n",
      "      ************************************************************\n",
      "      \n",
      "      Traceback (most recent call last):\n",
      "        File \"<string>\", line 2, in <module>\n",
      "        File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "        File \"C:\\Users\\Marwan Shamsan\\AppData\\Local\\Temp\\pip-install-a444wtr1\\cupy_fd9d91c0a655455596ca8a90198f47dd\\setup.py\", line 95, in <module>\n",
      "          ext_modules = cupy_setup_build.get_ext_modules(True, ctx)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\Marwan Shamsan\\AppData\\Local\\Temp\\pip-install-a444wtr1\\cupy_fd9d91c0a655455596ca8a90198f47dd\\install\\cupy_builder\\cupy_setup_build.py\", line 514, in get_ext_modules\n",
      "          extensions = make_extensions(ctx, compiler, use_cython)\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\Marwan Shamsan\\AppData\\Local\\Temp\\pip-install-a444wtr1\\cupy_fd9d91c0a655455596ca8a90198f47dd\\install\\cupy_builder\\cupy_setup_build.py\", line 363, in make_extensions\n",
      "          raise Exception('Your CUDA environment is invalid. '\n",
      "      Exception: Your CUDA environment is invalid. Please check above error log.\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for cupy\n",
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × python setup.py clean did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [59 lines of output]\n",
      "      Generating cache key from header files...\n",
      "      Cache key (1610 files matching C:\\Users\\Marwan Shamsan\\AppData\\Local\\Temp\\pip-install-a444wtr1\\cupy_fd9d91c0a655455596ca8a90198f47dd\\cupy\\_core\\include\\**): 8aad1231f702316b675b9ad296f56a95316298c2\n",
      "      Clearing directory: C:\\Users\\Marwan Shamsan\\AppData\\Local\\Temp\\pip-install-a444wtr1\\cupy_fd9d91c0a655455596ca8a90198f47dd\\cupy\\.data\n",
      "      Looking for NVTX: C:\\Program Files\\NVIDIA Corporation\\Nsight Systems *\\target-windows-x64\\nvtx\n",
      "      Using NVTX at: C:\\Program Files\\NVIDIA Corporation\\Nsight Systems 2024.6.2\\target-windows-x64\\nvtx\n",
      "      \n",
      "      -------- Configuring Module: cuda --------\n",
      "      Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "      **************************************************\n",
      "      *** WARNING: Cannot check compute capability\n",
      "      Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "      **************************************************\n",
      "      \n",
      "      ************************************************************\n",
      "      * CuPy Configuration Summary                               *\n",
      "      ************************************************************\n",
      "      \n",
      "      Build Environment:\n",
      "        Include directories: ['C:\\\\Users\\\\Marwan Shamsan\\\\AppData\\\\Local\\\\Temp\\\\pip-install-a444wtr1\\\\cupy_fd9d91c0a655455596ca8a90198f47dd\\\\cupy/_core/include\\\\cupy/_cccl/libcudacxx', 'C:\\\\Users\\\\Marwan Shamsan\\\\AppData\\\\Local\\\\Temp\\\\pip-install-a444wtr1\\\\cupy_fd9d91c0a655455596ca8a90198f47dd\\\\cupy/_core/include\\\\cupy/_cccl/thrust', 'C:\\\\Users\\\\Marwan Shamsan\\\\AppData\\\\Local\\\\Temp\\\\pip-install-a444wtr1\\\\cupy_fd9d91c0a655455596ca8a90198f47dd\\\\cupy/_core/include\\\\cupy/_cccl/cub', 'C:\\\\Users\\\\Marwan Shamsan\\\\AppData\\\\Local\\\\Temp\\\\pip-install-a444wtr1\\\\cupy_fd9d91c0a655455596ca8a90198f47dd\\\\cupy/_core/include', 'C:\\\\Program Files\\\\NVIDIA GPU Computing Toolkit\\\\CUDA\\\\v12.8\\\\include', 'C:\\\\Program Files\\\\NVIDIA Corporation\\\\Nsight Systems 2024.6.2\\\\target-windows-x64\\\\nvtx\\\\include']\n",
      "        Library directories: ['C:\\\\Program Files\\\\NVIDIA GPU Computing Toolkit\\\\CUDA\\\\v12.8\\\\bin', 'C:\\\\Program Files\\\\NVIDIA GPU Computing Toolkit\\\\CUDA\\\\v12.8\\\\lib\\\\x64']\n",
      "        nvcc command       : ['C:\\\\Program Files\\\\NVIDIA GPU Computing Toolkit\\\\CUDA\\\\v12.8\\\\bin/nvcc.exe']\n",
      "        hipcc command      : (not found)\n",
      "      \n",
      "      Environment Variables:\n",
      "        CFLAGS          : (none)\n",
      "        LDFLAGS         : (none)\n",
      "        LIBRARY_PATH    : (none)\n",
      "        CUDA_PATH       : C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.8\n",
      "        NVCC            : (none)\n",
      "        HIPCC           : (none)\n",
      "        ROCM_HOME       : (none)\n",
      "      \n",
      "      Modules:\n",
      "        cuda      : No\n",
      "          -> Include files not found: ['cublas_v2.h', 'cuda.h', 'cuda_profiler_api.h', 'cuda_runtime.h', 'cufft.h', 'curand.h', 'cusparse.h']\n",
      "          -> Check your CFLAGS environment variable.\n",
      "      \n",
      "      ERROR: CUDA could not be found on your system.\n",
      "      \n",
      "      HINT: You are trying to build CuPy from source, which is NOT recommended for general use.\n",
      "            Please consider using binary packages instead.\n",
      "      \n",
      "      Please refer to the Installation Guide for details:\n",
      "      https://docs.cupy.dev/en/stable/install.html\n",
      "      \n",
      "      ************************************************************\n",
      "      \n",
      "      Traceback (most recent call last):\n",
      "        File \"<string>\", line 2, in <module>\n",
      "        File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "        File \"C:\\Users\\Marwan Shamsan\\AppData\\Local\\Temp\\pip-install-a444wtr1\\cupy_fd9d91c0a655455596ca8a90198f47dd\\setup.py\", line 95, in <module>\n",
      "          ext_modules = cupy_setup_build.get_ext_modules(True, ctx)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\Marwan Shamsan\\AppData\\Local\\Temp\\pip-install-a444wtr1\\cupy_fd9d91c0a655455596ca8a90198f47dd\\install\\cupy_builder\\cupy_setup_build.py\", line 514, in get_ext_modules\n",
      "          extensions = make_extensions(ctx, compiler, use_cython)\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\Marwan Shamsan\\AppData\\Local\\Temp\\pip-install-a444wtr1\\cupy_fd9d91c0a655455596ca8a90198f47dd\\install\\cupy_builder\\cupy_setup_build.py\", line 363, in make_extensions\n",
      "          raise Exception('Your CUDA environment is invalid. '\n",
      "      Exception: Your CUDA environment is invalid. Please check above error log.\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed cleaning build dir for cupy\n",
      "ERROR: Could not build wheels for cupy, which is required to install pyproject.toml-based projects\n"
     ]
    }
   ],
   "source": [
    "pip install gradio scikit-image scikit-learn cupy matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7883\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7883/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import pickle\n",
    "import numpy as np\n",
    "import cupy as cp\n",
    "import cv2\n",
    "from skimage import morphology, filters, segmentation, exposure, feature, transform\n",
    "from scipy.ndimage import distance_transform_edt, label as nd_label\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from skimage.color import rgb2gray\n",
    "from joblib import load  # Import joblib\n",
    "\n",
    "# Load models\n",
    "models = {\n",
    "    \"Random Forest\": r\"C:\\Marwan APU\\Sem-2\\PR\\brine\\new_pkl\\best_random_forest_model.pkl\",\n",
    "    \"KNN\": r\"C:\\Marwan APU\\Sem-2\\PR\\brine\\new_pkl\\best_KNN_model.pkl\",\n",
    "    \"Decision Tree\": r\"C:\\Marwan APU\\Sem-2\\PR\\brine\\new_pkl\\Decision_tree_model.pkl\",\n",
    "    \"Gaussian NB\": r\"C:\\Marwan APU\\Sem-2\\PR\\brine\\new_pkl\\GaussianNB_model.pkl\",\n",
    "    \"Logistic Regression\": r\"C:\\Marwan APU\\Sem-2\\PR\\brine\\new_pkl\\logistic_regression_model.pkl\",\n",
    "    \"SVM\": r\"C:\\Marwan APU\\Sem-2\\PR\\brine\\new_pkl\\svm_model.pkl\",\n",
    "}\n",
    "\n",
    "loaded_models = {}\n",
    "for model_name, model_path in models.items():\n",
    "    loaded_models[model_name] = load(model_path)  # Use joblib.load()\n",
    "\n",
    "\n",
    "# Step 1: Anisotropic Diffusion Filter\n",
    "def anisotropic_diffusion_filter(image, alpha=0.1, beta=0.1, iterations=3):\n",
    "    image = cp.asarray(image.copy())  \n",
    "    for _ in range(iterations):\n",
    "        gradient_magnitude = cp.gradient(image)\n",
    "        c = 1.0 / (1.0 + (gradient_magnitude[0] / beta) ** 2)\n",
    "        diff_north = cp.roll(image, shift=1, axis=0) - image\n",
    "        diff_south = cp.roll(image, shift=-1, axis=0) - image\n",
    "        diff_east = cp.roll(image, shift=1, axis=1) - image\n",
    "        diff_west = cp.roll(image, shift=-1, axis=1) - image\n",
    "        image += alpha * (c * (diff_north + diff_south + diff_east + diff_west))\n",
    "    return cp.asnumpy(image)  \n",
    "\n",
    "# Step 2: Skull Stripping\n",
    "def skull_stripping(image, se_closing=None, se_erosion=None, skull_remove_area=1500):\n",
    "    if se_closing is None:\n",
    "        se_closing = morphology.disk(15)\n",
    "    if se_erosion is None:\n",
    "        se_erosion = morphology.disk(30)\n",
    "    threshold_value = filters.threshold_otsu(image)\n",
    "    binary_image = image > threshold_value\n",
    "    filled_image = morphology.closing(binary_image, se_closing)\n",
    "    filled_image = morphology.remove_small_holes(filled_image, area_threshold=skull_remove_area)\n",
    "    eroded_image = morphology.erosion(filled_image, se_erosion)\n",
    "    return np.where(eroded_image, image, 0)\n",
    "\n",
    "# Step 3: Top-Hat Filtering\n",
    "def top_hat_filtering(image, kernel_size=30):\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (kernel_size, kernel_size))\n",
    "    return cv2.morphologyEx(image, cv2.MORPH_TOPHAT, kernel)\n",
    "\n",
    "# Step 4: Contrast Enhancement\n",
    "def contrast_enhancement(image):\n",
    "    contrasted_image = exposure.equalize_hist(image)\n",
    "    return ((contrasted_image - np.min(contrasted_image)) / (np.max(contrasted_image) - np.min(contrasted_image)) * 255).astype(np.uint8)\n",
    "\n",
    "# Step 5: Binary Segmentation\n",
    "def get_binary(image, thresh=None):\n",
    "    if thresh is None:\n",
    "        thresh = filters.threshold_otsu(image)\n",
    "    return image > thresh, thresh\n",
    "\n",
    "# Step 6: Watershed Segmentation\n",
    "def watershed_segmentation(image, se_peak_local=np.ones((3, 3))):\n",
    "    image = cp.asarray(image)\n",
    "    distance = cp.asarray(distance_transform_edt(cp.asnumpy(image)))\n",
    "    local_maxi = feature.peak_local_max(cp.asnumpy(distance), labels=cp.asnumpy(image), footprint=se_peak_local, exclude_border=False)\n",
    "    local_maxi_mask = cp.zeros_like(image, dtype=bool)\n",
    "    local_maxi_mask[tuple(np.array(local_maxi).T)] = True\n",
    "    markers = nd_label(cp.asnumpy(local_maxi_mask))[0]\n",
    "    segmented_image = segmentation.watershed(-cp.asnumpy(distance), markers, mask=cp.asnumpy(image))\n",
    "    return cp.asnumpy(segmented_image), np.max(segmented_image)\n",
    "\n",
    "# Step 7: Morphological Operations\n",
    "def apply_morphological_operations(image, kernel_size=5):\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (kernel_size, kernel_size))\n",
    "    image = image.astype(np.uint8)\n",
    "    closed = cv2.morphologyEx(image, cv2.MORPH_CLOSE, kernel)\n",
    "    opened = cv2.morphologyEx(closed, cv2.MORPH_OPEN, kernel)\n",
    "    return closed, opened\n",
    "\n",
    "# Full preprocessing pipeline\n",
    "def preprocess_pipeline(image):\n",
    "    # Convert to grayscale\n",
    "    grayscale_image = rgb2gray(image)\n",
    "\n",
    "    # Apply the full pipeline\n",
    "    adf_filtered_image = anisotropic_diffusion_filter(grayscale_image)\n",
    "    skull_stripped_image = skull_stripping(adf_filtered_image)\n",
    "    tophat_image = top_hat_filtering(skull_stripped_image)\n",
    "    contrasted_image = contrast_enhancement(tophat_image)\n",
    "    binary_image, thresh = get_binary(contrasted_image, thresh=230)\n",
    "    segmented_image, nbr_labels = watershed_segmentation(binary_image, morphology.disk(10))\n",
    "    closed_image_post, opened_image = apply_morphological_operations(segmented_image)\n",
    "\n",
    "    # Resize to match model input (256x256)\n",
    "    resized_image = transform.resize(binary_image, (256, 256))\n",
    "\n",
    "    # Flatten the image for model input\n",
    "    flattened_image = resized_image.flatten().reshape(1, -1)\n",
    "\n",
    "    # Scale features\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_features = scaler.fit_transform(flattened_image)\n",
    "\n",
    "    return scaled_features, resized_image, contrasted_image\n",
    "\n",
    "# Classification Function\n",
    "def classify_image(image, model_name):\n",
    "    # Preprocess image\n",
    "    scaled_features, preprocessed_image, contrast_image = preprocess_pipeline(image)\n",
    "\n",
    "    # Get selected model\n",
    "    model = loaded_models[model_name]\n",
    "\n",
    "    # Make prediction\n",
    "    prediction = model.predict(scaled_features)\n",
    "\n",
    "    return preprocessed_image, f\"Predicted Label: {prediction[0]}\"\n",
    "\n",
    "# GUI\n",
    "def gui():\n",
    "    with gr.Blocks() as demo:\n",
    "        gr.Markdown(\"## Image Classification Demo\")\n",
    "\n",
    "        with gr.Row():\n",
    "            with gr.Column():\n",
    "                image_input = gr.Image(label=\"Upload a Photo\", type=\"numpy\")\n",
    "                preprocess_button = gr.Button(\"Preprocess\")\n",
    "                preprocess_output = gr.Image(label=\"Preprocessed Image Preview\")\n",
    "            with gr.Column():\n",
    "                model_dropdown = gr.Dropdown(\n",
    "                    choices=list(models.keys()), label=\"Select Model\", value=\"Random Forest\"\n",
    "                )\n",
    "                classify_button = gr.Button(\"Classify\")\n",
    "                prediction_output = gr.Textbox(label=\"Predicted Label\", interactive=False)\n",
    "\n",
    "        # Preprocessing\n",
    "        preprocess_button.click(\n",
    "            lambda image: preprocess_pipeline(image)[1], inputs=image_input, outputs=preprocess_output\n",
    "        )\n",
    "\n",
    "        # Classification\n",
    "        classify_button.click(\n",
    "            classify_image,\n",
    "            inputs=[image_input, model_dropdown],\n",
    "            outputs=[preprocess_output, prediction_output],\n",
    "        )\n",
    "\n",
    "    demo.launch()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    gui()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7884\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7884/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import pickle\n",
    "import numpy as np\n",
    "import cupy as cp\n",
    "import cv2\n",
    "from skimage import morphology, filters, segmentation, exposure, feature, transform\n",
    "from scipy.ndimage import distance_transform_edt, label as nd_label\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from skimage.color import rgb2gray\n",
    "from joblib import load\n",
    "\n",
    "# Load models\n",
    "models = {\n",
    "    \"Random Forest\": r\"C:\\Marwan APU\\Sem-2\\PR\\brine\\new_pkl\\best_random_forest_model.pkl\",\n",
    "    \"KNN\": r\"C:\\Marwan APU\\Sem-2\\PR\\brine\\new_pkl\\best_KNN_model.pkl\",\n",
    "    \"Decision Tree\": r\"C:\\Marwan APU\\Sem-2\\PR\\brine\\new_pkl\\Decision_tree_model.pkl\",\n",
    "    \"Gaussian NB\": r\"C:\\Marwan APU\\Sem-2\\PR\\brine\\new_pkl\\GaussianNB_model.pkl\",\n",
    "    \"Logistic Regression\": r\"C:\\Marwan APU\\Sem-2\\PR\\brine\\new_pkl\\logistic_regression_model.pkl\",\n",
    "    \"SVM\": r\"C:\\Marwan APU\\Sem-2\\PR\\brine\\new_pkl\\svm_model.pkl\",\n",
    "}\n",
    "\n",
    "loaded_models = {}\n",
    "for model_name, model_path in models.items():\n",
    "    loaded_models[model_name] = load(model_path)\n",
    "\n",
    "def preprocess_pipeline(image):\n",
    "    try:\n",
    "        # Convert to grayscale\n",
    "        grayscale_image = rgb2gray(image)\n",
    "\n",
    "        # Apply preprocessing steps\n",
    "        adf_filtered_image = anisotropic_diffusion_filter(grayscale_image)\n",
    "        skull_stripped_image = skull_stripping(adf_filtered_image)\n",
    "        tophat_image = top_hat_filtering(skull_stripped_image)\n",
    "        contrasted_image = contrast_enhancement(tophat_image)\n",
    "        binary_image, _ = get_binary(contrasted_image, thresh=230)\n",
    "        segmented_image, _ = watershed_segmentation(binary_image, morphology.disk(10))\n",
    "        closed_image_post, _ = apply_morphological_operations(segmented_image)\n",
    "\n",
    "        # Resize for model input\n",
    "        resized_image = transform.resize(binary_image, (256, 256))\n",
    "        resized_image = (resized_image * 255).astype(np.uint8)  # Ensure uint8 format\n",
    "\n",
    "        # Flatten and scale the image\n",
    "        flattened_image = resized_image.flatten().reshape(1, -1)\n",
    "        scaler = MinMaxScaler()\n",
    "        scaled_features = scaler.fit_transform(flattened_image)\n",
    "\n",
    "        return scaled_features, resized_image, contrasted_image\n",
    "    except Exception as e:\n",
    "        print(f\"Error in preprocessing pipeline: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def classify_image(image, model_name):\n",
    "    try:\n",
    "        scaled_features, preprocessed_image, contrast_image = preprocess_pipeline(image)\n",
    "\n",
    "        # Ensure preprocessed_image is in uint8 for Gradio\n",
    "        preprocessed_image = (preprocessed_image * 255).astype(np.uint8)\n",
    "\n",
    "        # Predict using the selected model\n",
    "        model = loaded_models[model_name]\n",
    "        prediction = model.predict(scaled_features)\n",
    "\n",
    "        return preprocessed_image, f\"Predicted Label: {prediction[0]}\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error in classification: {e}\")\n",
    "        return None, \"Error\"\n",
    "\n",
    "\n",
    "# GUI\n",
    "def gui():\n",
    "    with gr.Blocks() as demo:\n",
    "        gr.Markdown(\"## Image Classification Demo\")\n",
    "\n",
    "        with gr.Row():\n",
    "            with gr.Column():\n",
    "                image_input = gr.Image(label=\"Upload a Photo\", type=\"numpy\")\n",
    "                preprocess_button = gr.Button(\"Preprocess\")\n",
    "                preprocess_output = gr.Image(label=\"Preprocessed Image Preview\")\n",
    "            with gr.Column():\n",
    "                model_dropdown = gr.Dropdown(\n",
    "                    choices=list(models.keys()), label=\"Select Model\", value=\"Random Forest\"\n",
    "                )\n",
    "                classify_button = gr.Button(\"Classify\")\n",
    "                prediction_output = gr.Textbox(label=\"Predicted Label\", interactive=False)\n",
    "\n",
    "        # Preprocessing\n",
    "        preprocess_button.click(\n",
    "            lambda image: preprocess_pipeline(image)[1], inputs=image_input, outputs=preprocess_output\n",
    "        )\n",
    "\n",
    "        # Classification\n",
    "        classify_button.click(\n",
    "            classify_image,\n",
    "            inputs=[image_input, model_dropdown],\n",
    "            outputs=[preprocess_output, prediction_output],\n",
    "        )\n",
    "\n",
    "    demo.launch()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    gui()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7885\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7885/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import numpy as np\n",
    "import cupy as cp\n",
    "import cv2\n",
    "from skimage import morphology, filters, segmentation, exposure, transform, feature  # 🔥 Added `feature`\n",
    "from skimage.color import rgb2gray\n",
    "from scipy.ndimage import distance_transform_edt, label as nd_label\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from joblib import load\n",
    "\n",
    "\n",
    "# Load models\n",
    "models = {\n",
    "    \"Random Forest\": r\"C:\\Marwan APU\\Sem-2\\PR\\brine\\new_pkl\\best_random_forest_model.pkl\",\n",
    "    \"KNN\": r\"C:\\Marwan APU\\Sem-2\\PR\\brine\\new_pkl\\best_KNN_model.pkl\",\n",
    "    \"Decision Tree\": r\"C:\\Marwan APU\\Sem-2\\PR\\brine\\new_pkl\\Decision_tree_model.pkl\",\n",
    "    \"Gaussian NB\": r\"C:\\Marwan APU\\Sem-2\\PR\\brine\\new_pkl\\GaussianNB_model.pkl\",\n",
    "    \"Logistic Regression\": r\"C:\\Marwan APU\\Sem-2\\PR\\brine\\logistic_regression_model.pkl\",\n",
    "    \"SVM\": r\"C:\\Marwan APU\\Sem-2\\PR\\brine\\new_pkl\\svm_model.pkl\",\n",
    "}\n",
    "\n",
    "loaded_models = {}\n",
    "for model_name, model_path in models.items():\n",
    "    loaded_models[model_name] = load(model_path)\n",
    "\n",
    "# Step 1: Anisotropic Diffusion Filter\n",
    "\n",
    "# Step 1: Anisotropic Diffusion Filter (ADF)\n",
    "# Step 1: Anisotropic Diffusion Filter\n",
    "def anisotropic_diffusion_filter(image, alpha=0.1, beta=0.1, iterations=3):\n",
    "    image = cp.asarray(image.copy())  # Move image to GPU\n",
    "    for _ in range(iterations):\n",
    "        gradient_magnitude = cp.gradient(image)\n",
    "        c = 1.0 / (1.0 + (gradient_magnitude[0] / beta) ** 2)\n",
    "        diff_north = cp.roll(image, shift=1, axis=0) - image\n",
    "        diff_south = cp.roll(image, shift=-1, axis=0) - image\n",
    "        diff_east = cp.roll(image, shift=1, axis=1) - image\n",
    "        diff_west = cp.roll(image, shift=-1, axis=1) - image\n",
    "        image += alpha * (c * (diff_north + diff_south + diff_east + diff_west))\n",
    "    return cp.asnumpy(image)  # Move back to CPU\n",
    "\n",
    "# Step 2: Skull Stripping\n",
    "def skull_stripping(image, se_closing=None, se_erosion=None, skull_remove_area=1500):\n",
    "    if se_closing is None:\n",
    "        se_closing = morphology.disk(15)\n",
    "    if se_erosion is None:\n",
    "        se_erosion = morphology.disk(30)\n",
    "    threshold_value = filters.threshold_otsu(image)\n",
    "    binary_image = image > threshold_value\n",
    "    filled_image = morphology.closing(binary_image, se_closing)\n",
    "    filled_image = morphology.remove_small_holes(filled_image, area_threshold=skull_remove_area)\n",
    "    eroded_image = morphology.erosion(filled_image, se_erosion)\n",
    "    return np.where(eroded_image, image, 0)\n",
    "\n",
    "# Step 3: Top-Hat Filtering\n",
    "def top_hat_filtering(image, kernel_size=30):\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (kernel_size, kernel_size))\n",
    "    return cv2.morphologyEx(image, cv2.MORPH_TOPHAT, kernel)\n",
    "\n",
    "# Step 4: Contrast Enhancement\n",
    "def contrast_enhancement(image):\n",
    "    contrasted_image = exposure.equalize_hist(image)\n",
    "    return ((contrasted_image - np.min(contrasted_image)) / (np.max(contrasted_image) - np.min(contrasted_image)) * 255).astype(np.uint8)\n",
    "\n",
    "# Step 5: Binary Segmentation\n",
    "def get_binary(image, thresh=None):\n",
    "    if thresh is None:\n",
    "        thresh = filters.threshold_otsu(image)\n",
    "    return image > thresh, thresh\n",
    "\n",
    "# Step 6: Watershed Segmentation\n",
    "def watershed_segmentation(image, se_peak_local=np.ones((3, 3))):\n",
    "    image = cp.asarray(image)\n",
    "    distance = cp.asarray(distance_transform_edt(cp.asnumpy(image)))\n",
    "    local_maxi = feature.peak_local_max(cp.asnumpy(distance), labels=cp.asnumpy(image), footprint=se_peak_local, exclude_border=False)\n",
    "    local_maxi_mask = cp.zeros_like(image, dtype=bool)\n",
    "    local_maxi_mask[tuple(np.array(local_maxi).T)] = True\n",
    "    markers = nd_label(cp.asnumpy(local_maxi_mask))[0]\n",
    "    segmented_image = segmentation.watershed(-cp.asnumpy(distance), markers, mask=cp.asnumpy(image))\n",
    "    return cp.asnumpy(segmented_image), np.max(segmented_image)\n",
    "\n",
    "# Step 7: Morphological Operations\n",
    "def apply_morphological_operations(image, kernel_size=5):\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (kernel_size, kernel_size))\n",
    "    image = image.astype(np.uint8)\n",
    "    closed = cv2.morphologyEx(image, cv2.MORPH_CLOSE, kernel)\n",
    "    opened = cv2.morphologyEx(closed, cv2.MORPH_OPEN, kernel)\n",
    "    return closed, opened\n",
    "\n",
    "# Full preprocessing pipeline\n",
    "# Full preprocessing pipeline\n",
    "def preprocess_pipeline(image):\n",
    "    try:\n",
    "        # Convert to grayscale\n",
    "        grayscale_image = rgb2gray(image)\n",
    "\n",
    "        # Apply preprocessing steps\n",
    "        adf_filtered_image = anisotropic_diffusion_filter(grayscale_image)\n",
    "        skull_stripped_image = skull_stripping(adf_filtered_image)\n",
    "        tophat_image = top_hat_filtering(skull_stripped_image)\n",
    "        contrasted_image = contrast_enhancement(tophat_image)\n",
    "        binary_image, _ = get_binary(contrasted_image, thresh=230)\n",
    "        segmented_image, _ = watershed_segmentation(binary_image, morphology.disk(10))\n",
    "        closed_image_post, opened_image_post = apply_morphological_operations(segmented_image)\n",
    "\n",
    "        # Resize the opened image for display\n",
    "        resized_opened_image = transform.resize(opened_image_post, (128, 128))\n",
    "        resized_opened_image = (resized_opened_image * 255).astype(np.uint8)  # Ensure uint8 format\n",
    "\n",
    "        # Flatten and scale the image for the model\n",
    "        flattened_image = resized_opened_image.flatten().reshape(1, -1)\n",
    "        scaler = MinMaxScaler()\n",
    "        scaled_features = scaler.fit_transform(flattened_image)\n",
    "\n",
    "        return scaled_features, resized_opened_image, contrasted_image\n",
    "    except Exception as e:\n",
    "        print(f\"Error in preprocessing pipeline: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "# Classification Function\n",
    "def classify_image(image, model_name):\n",
    "    try:\n",
    "        # Preprocess image\n",
    "        scaled_features, opened_image, contrast_image = preprocess_pipeline(image)\n",
    "\n",
    "        # Ensure opened_image is in uint8 for Gradio\n",
    "        opened_image = (opened_image * 255).astype(np.uint8)\n",
    "\n",
    "        # Predict using the selected model\n",
    "        model = loaded_models[model_name]\n",
    "        prediction = model.predict(scaled_features)\n",
    "\n",
    "        return opened_image, f\"Predicted Label: {prediction[0]}\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error in classification: {e}\")\n",
    "        return None, \"Error\"\n",
    "\n",
    "\n",
    "# GUI\n",
    "def gui():\n",
    "    with gr.Blocks() as demo:\n",
    "        gr.Markdown(\"## Image Classification Demo\")\n",
    "\n",
    "        with gr.Row():\n",
    "            with gr.Column():\n",
    "                image_input = gr.Image(label=\"Upload a Photo\", type=\"numpy\")\n",
    "                preprocess_button = gr.Button(\"Preprocess\")\n",
    "                preprocess_output = gr.Image(label=\"Preprocessed Image Preview\")\n",
    "            with gr.Column():\n",
    "                model_dropdown = gr.Dropdown(\n",
    "                    choices=list(models.keys()), label=\"Select Model\", value=\"Random Forest\"\n",
    "                )\n",
    "                classify_button = gr.Button(\"Classify\")\n",
    "                prediction_output = gr.Textbox(label=\"Predicted Label\", interactive=False)\n",
    "\n",
    "        # Preprocessing\n",
    "        preprocess_button.click(\n",
    "            lambda image: preprocess_pipeline(image)[1], inputs=image_input, outputs=preprocess_output\n",
    "        )\n",
    "\n",
    "        # Classification\n",
    "        classify_button.click(\n",
    "            classify_image,\n",
    "            inputs=[image_input, model_dropdown],\n",
    "            outputs=[preprocess_output, prediction_output],\n",
    "        )\n",
    "\n",
    "    demo.launch()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    gui()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7886\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7886/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import numpy as np\n",
    "import cupy as cp\n",
    "import cv2\n",
    "from skimage import morphology, filters, segmentation, exposure, transform, feature\n",
    "from skimage.color import rgb2gray\n",
    "from scipy.ndimage import distance_transform_edt, label as nd_label\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from joblib import load\n",
    "\n",
    "# Load models\n",
    "models = {\n",
    "    \"Random Forest\": r\"C:\\Marwan APU\\Sem-2\\PR\\brine\\new_pkl\\best_random_forest_model.pkl\",\n",
    "    \"KNN\": r\"C:\\Marwan APU\\Sem-2\\PR\\brine\\new_pkl\\best_KNN_model.pkl\",\n",
    "    \"Decision Tree\": r\"C:\\Marwan APU\\Sem-2\\PR\\brine\\new_pkl\\Decision_tree_model.pkl\",\n",
    "    \"Gaussian NB\": r\"C:\\Marwan APU\\Sem-2\\PR\\brine\\new_pkl\\GaussianNB_model.pkl\",\n",
    "    \"Logistic Regression\": r\"C:\\Marwan APU\\Sem-2\\PR\\brine\\new_pkl\\logistic_regression_model.pkl\",\n",
    "    \"SVM\": r\"C:\\Marwan APU\\Sem-2\\PR\\brine\\new_pkl\\svm_model.pkl\",\n",
    "}\n",
    "\n",
    "loaded_models = {model_name: load(model_path) for model_name, model_path in models.items()}\n",
    "\n",
    "# Step 1: Anisotropic Diffusion Filter\n",
    "def anisotropic_diffusion_filter(image, alpha=0.1, beta=0.1, iterations=3):\n",
    "    image = cp.asarray(image.copy())  # Move image to GPU\n",
    "    for _ in range(iterations):\n",
    "        gradient_magnitude = cp.gradient(image)\n",
    "        c = 1.0 / (1.0 + (gradient_magnitude[0] / beta) ** 2)\n",
    "        diff_north = cp.roll(image, shift=1, axis=0) - image\n",
    "        diff_south = cp.roll(image, shift=-1, axis=0) - image\n",
    "        diff_east = cp.roll(image, shift=1, axis=1) - image\n",
    "        diff_west = cp.roll(image, shift=-1, axis=1) - image\n",
    "        image += alpha * (c * (diff_north + diff_south + diff_east + diff_west))\n",
    "    return cp.asnumpy(image)  # Move back to CPU\n",
    "\n",
    "# Step 2: Skull Stripping\n",
    "def skull_stripping(image, se_closing=None, se_erosion=None, skull_remove_area=1500):\n",
    "    if se_closing is None:\n",
    "        se_closing = morphology.disk(15)\n",
    "    if se_erosion is None:\n",
    "        se_erosion = morphology.disk(30)\n",
    "    threshold_value = filters.threshold_otsu(image)\n",
    "    binary_image = image > threshold_value\n",
    "    filled_image = morphology.closing(binary_image, se_closing)\n",
    "    filled_image = morphology.remove_small_holes(filled_image, area_threshold=skull_remove_area)\n",
    "    eroded_image = morphology.erosion(filled_image, se_erosion)\n",
    "    return np.where(eroded_image, image, 0)\n",
    "\n",
    "# Step 3: Top-Hat Filtering\n",
    "def top_hat_filtering(image, kernel_size=30):\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (kernel_size, kernel_size))\n",
    "    return cv2.morphologyEx(image, cv2.MORPH_TOPHAT, kernel)\n",
    "\n",
    "# Step 4: Contrast Enhancement\n",
    "def contrast_enhancement(image):\n",
    "    contrasted_image = exposure.equalize_hist(image)\n",
    "    return ((contrasted_image - np.min(contrasted_image)) / (np.max(contrasted_image) - np.min(contrasted_image)) * 255).astype(np.uint8)\n",
    "\n",
    "# Step 5: Binary Segmentation\n",
    "def get_binary(image, thresh=None):\n",
    "    if thresh is None:\n",
    "        thresh = filters.threshold_otsu(image)\n",
    "    return image > thresh, thresh\n",
    "\n",
    "# Step 6: Watershed Segmentation\n",
    "def watershed_segmentation(image, se_peak_local=np.ones((3, 3))):\n",
    "    image = cp.asarray(image)\n",
    "    distance = cp.asarray(distance_transform_edt(cp.asnumpy(image)))\n",
    "    local_maxi = feature.peak_local_max(cp.asnumpy(distance), labels=cp.asnumpy(image), footprint=se_peak_local, exclude_border=False)\n",
    "    local_maxi_mask = cp.zeros_like(image, dtype=bool)\n",
    "    local_maxi_mask[tuple(np.array(local_maxi).T)] = True\n",
    "    markers = nd_label(cp.asnumpy(local_maxi_mask))[0]\n",
    "    segmented_image = segmentation.watershed(-cp.asnumpy(distance), markers, mask=cp.asnumpy(image))\n",
    "    return cp.asnumpy(segmented_image), np.max(segmented_image)\n",
    "\n",
    "# Step 7: Morphological Operations\n",
    "def apply_morphological_operations(image, kernel_size=5):\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (kernel_size, kernel_size))\n",
    "    image = image.astype(np.uint8)\n",
    "    closed = cv2.morphologyEx(image, cv2.MORPH_CLOSE, kernel)\n",
    "    opened = cv2.morphologyEx(closed, cv2.MORPH_OPEN, kernel)\n",
    "    return closed, opened\n",
    "\n",
    "# Full preprocessing pipeline\n",
    "def preprocess_pipeline(image):\n",
    "    try:\n",
    "        grayscale_image = rgb2gray(image)\n",
    "        adf_filtered_image = anisotropic_diffusion_filter(grayscale_image)\n",
    "        skull_stripped_image = skull_stripping(adf_filtered_image)\n",
    "        tophat_image = top_hat_filtering(skull_stripped_image)\n",
    "        contrasted_image = contrast_enhancement(tophat_image)\n",
    "        binary_image, _ = get_binary(contrasted_image, thresh=230)\n",
    "        segmented_image, _ = watershed_segmentation(binary_image, morphology.disk(10))\n",
    "        closed_image_post, opened_image_post = apply_morphological_operations(segmented_image)\n",
    "\n",
    "        # ✅ Resize to 256x256 (ensures 65536 features)\n",
    "        resized_opened_image = transform.resize(opened_image_post, (256, 256))\n",
    "        resized_opened_image = (resized_opened_image * 255).astype(np.uint8)\n",
    "\n",
    "        # ✅ Flatten and scale\n",
    "        flattened_image = resized_opened_image.flatten().reshape(1, -1)\n",
    "        scaler = MinMaxScaler()\n",
    "        scaled_features = scaler.fit_transform(flattened_image)\n",
    "\n",
    "        return scaled_features, resized_opened_image\n",
    "    except Exception as e:\n",
    "        print(f\"Error in preprocessing pipeline: {e}\")\n",
    "        raise\n",
    "\n",
    "# Classification Function with Dynamic Feature Handling\n",
    "def classify_image(image, model_name):\n",
    "    try:\n",
    "        scaled_features, opened_image = preprocess_pipeline(image)\n",
    "        model = loaded_models[model_name]\n",
    "\n",
    "        # ✅ Dynamically match feature size\n",
    "        expected_size = model.n_features_in_\n",
    "        if scaled_features.shape[1] != expected_size:\n",
    "            print(f\"Resizing from {scaled_features.shape[1]} to {expected_size}\")\n",
    "            scaled_features = np.resize(scaled_features, (1, expected_size))  \n",
    "\n",
    "        prediction = model.predict(scaled_features)\n",
    "        return opened_image, f\"Predicted Label: {prediction[0]}\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error in classification: {e}\")\n",
    "        return None, \"Error\"\n",
    "\n",
    "# GUI\n",
    "def gui():\n",
    "    with gr.Blocks() as demo:\n",
    "        gr.Markdown(\"## Image Classification Demo\")\n",
    "        with gr.Row():\n",
    "            with gr.Column():\n",
    "                image_input = gr.Image(label=\"Upload a Photo\", type=\"numpy\")\n",
    "                classify_button = gr.Button(\"Classify\")\n",
    "                preprocess_output = gr.Image(label=\"Preprocessed Image Preview\")\n",
    "            with gr.Column():\n",
    "                model_dropdown = gr.Dropdown(choices=list(models.keys()), label=\"Select Model\", value=\"Random Forest\")\n",
    "                prediction_output = gr.Textbox(label=\"Predicted Label\", interactive=False)\n",
    "\n",
    "        classify_button.click(classify_image, inputs=[image_input, model_dropdown], outputs=[preprocess_output, prediction_output])\n",
    "\n",
    "    demo.launch()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    gui()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7887\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7887/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import numpy as np\n",
    "import cupy as cp\n",
    "import cv2\n",
    "from skimage import morphology, filters, segmentation, exposure, transform, feature\n",
    "from skimage.color import rgb2gray\n",
    "from scipy.ndimage import distance_transform_edt, label as nd_label\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from joblib import load\n",
    "\n",
    "# Load models\n",
    "models = {\n",
    "    \"Random Forest\": r\"C:\\Marwan APU\\Sem-2\\PR\\brine\\new_pkl\\best_random_forest_model.pkl\",\n",
    "    \"KNN\": r\"C:\\Marwan APU\\Sem-2\\PR\\brine\\new_pkl\\best_KNN_model.pkl\",\n",
    "    \"Decision Tree\": r\"C:\\Marwan APU\\Sem-2\\PR\\brine\\new_pkl\\Decision_tree_model.pkl\",\n",
    "    \"Gaussian NB\": r\"C:\\Marwan APU\\Sem-2\\PR\\brine\\new_pkl\\GaussianNB_model.pkl\",\n",
    "    \"Logistic Regression\": r\"C:\\Marwan APU\\Sem-2\\PR\\brine\\new_pkl\\logistic_regression_model.pkl\",\n",
    "    \"SVM\": r\"C:\\Marwan APU\\Sem-2\\PR\\brine\\new_pkl\\svm_model.pkl\",\n",
    "}\n",
    "\n",
    "loaded_models = {model_name: load(model_path) for model_name, model_path in models.items()}\n",
    "\n",
    "\n",
    "# Step 1: Anisotropic Diffusion Filter (ADF)\n",
    "def anisotropic_diffusion_filter(image, alpha=0.1, beta=0.1, iterations=3):\n",
    "    image = img_as_float(image.copy())\n",
    "    for _ in range(iterations):\n",
    "        gradient_magnitude = gaussian_gradient_magnitude(image, sigma=1)\n",
    "        c = 1.0 / (1.0 + (gradient_magnitude / beta) ** 2)\n",
    "        diff_north = convolve(image, np.array([[0, 1, 0], [0, -1, 0], [0, 0, 0]]))\n",
    "        diff_south = convolve(image, np.array([[0, 0, 0], [0, -1, 0], [0, 1, 0]]))\n",
    "        diff_east = convolve(image, np.array([[0, 0, 0], [0, -1, 1], [0, 0, 0]]))\n",
    "        diff_west = convolve(image, np.array([[0, 0, 0], [1, -1, 0], [0, 0, 0]]))\n",
    "        image += alpha * (c * diff_north + c * diff_south + c * diff_east + c * diff_west)\n",
    "    return img_as_ubyte(image)\n",
    "\n",
    "# Step 2: Skull Stripping\n",
    "def skull_stripping(image, se_closing=None, se_erosion=None, skull_remove_area=2000):\n",
    "    if se_closing is None:\n",
    "        se_closing = morphology.disk(15)\n",
    "    if se_erosion is None:\n",
    "        se_erosion = morphology.disk(30)\n",
    "    threshold_value = filters.threshold_otsu(image)\n",
    "    binary_image = image > threshold_value\n",
    "    filled_image = morphology.closing(binary_image, se_closing)\n",
    "    filled_image = morphology.remove_small_holes(filled_image, area_threshold=skull_remove_area)\n",
    "    eroded_image = morphology.erosion(filled_image, se_erosion)\n",
    "    return np.where(eroded_image, image, 0)\n",
    "\n",
    "# Step 3: Top-Hat Filtering\n",
    "def top_hat_filtering(image, disk_size=30):\n",
    "    footprint = morphology.disk(disk_size)\n",
    "    return morphology.white_tophat(image, footprint)\n",
    "\n",
    "# Step 4: Contrast Enhancement\n",
    "def contrast_enhancement(image):\n",
    "    contrasted_image = exposure.equalize_hist(image)\n",
    "    contrasted_image = (contrasted_image - np.min(contrasted_image)) / (np.max(contrasted_image) - np.min(contrasted_image))\n",
    "    return img_as_ubyte(contrasted_image)\n",
    "\n",
    "# Step 5: Binary Segmentation\n",
    "def get_binary(image, thresh=None):\n",
    "    if thresh is None:\n",
    "        thresh = filters.threshold_otsu(image)\n",
    "    binary_image = image > thresh\n",
    "    return binary_image, thresh\n",
    "\n",
    "# Step 6: Watershed Segmentation\n",
    "def watershed_segmentation(image, se_peak_local=np.ones((3, 3))):\n",
    "    distance = distance_transform_edt(image)\n",
    "    local_maxi = feature.peak_local_max(distance, labels=image, footprint=se_peak_local, exclude_border=False)\n",
    "    local_maxi_mask = np.zeros_like(image, dtype=bool)\n",
    "    local_maxi_mask[tuple(local_maxi.T)] = True\n",
    "    markers = nd_label(local_maxi_mask)[0]  # Use `nd_label` here\n",
    "    segmented_image = segmentation.watershed(-distance, markers, mask=image)\n",
    "    nbr_labels = np.max(segmented_image)\n",
    "    return segmented_image, nbr_labels\n",
    "\n",
    "\n",
    "# Step 7: Morphological Operations\n",
    "def apply_morphological_operations(segmented_image):\n",
    "    if not isinstance(segmented_image, np.ndarray) or segmented_image.ndim != 2:\n",
    "        return None, None  # Prevent errors if input is invalid\n",
    "    \n",
    "    closed_image = morphology.closing(segmented_image, morphology.disk(6))\n",
    "    opened_image = morphology.opening(closed_image, morphology.disk(5))\n",
    "    \n",
    "    return closed_image, opened_image\n",
    "\n",
    "\n",
    "# Full preprocessing pipeline\n",
    "def preprocess_pipeline(image):\n",
    "    try:\n",
    "        grayscale_image = rgb2gray(image)\n",
    "        adf_filtered_image = anisotropic_diffusion_filter(grayscale_image)\n",
    "        skull_stripped_image = skull_stripping(adf_filtered_image)\n",
    "        tophat_image = top_hat_filtering(skull_stripped_image)\n",
    "        contrasted_image = contrast_enhancement(tophat_image)\n",
    "        binary_image, _ = get_binary(contrasted_image, thresh=230)\n",
    "        segmented_image, _ = watershed_segmentation(binary_image, morphology.disk(10))\n",
    "        closed_image_post, opened_image_post = apply_morphological_operations(segmented_image)\n",
    "\n",
    "        # ✅ Resize to 256x256 (ensures 65536 features)\n",
    "        resized_opened_image = transform.resize(opened_image_post, (256, 256))\n",
    "        resized_opened_image = (resized_opened_image * 255).astype(np.uint8)\n",
    "\n",
    "        # ✅ Flatten and scale\n",
    "        flattened_image = resized_opened_image.flatten().reshape(1, -1)\n",
    "        scaler = MinMaxScaler()\n",
    "        scaled_features = scaler.fit_transform(flattened_image)\n",
    "\n",
    "        return scaled_features, resized_opened_image\n",
    "    except Exception as e:\n",
    "        print(f\"Error in preprocessing pipeline: {e}\")\n",
    "        raise\n",
    "\n",
    "# Classification Function with Dynamic Feature Handling\n",
    "def classify_image(image, model_name):\n",
    "    try:\n",
    "        scaled_features, opened_image = preprocess_pipeline(image)\n",
    "        model = loaded_models[model_name]\n",
    "\n",
    "        # ✅ Dynamically match feature size\n",
    "        expected_size = model.n_features_in_\n",
    "        if scaled_features.shape[1] != expected_size:\n",
    "            print(f\"Resizing from {scaled_features.shape[1]} to {expected_size}\")\n",
    "            scaled_features = np.resize(scaled_features, (1, expected_size))  \n",
    "\n",
    "        prediction = model.predict(scaled_features)\n",
    "        return opened_image, f\"Predicted Label: {prediction[0]}\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error in classification: {e}\")\n",
    "        return None, \"Error\"\n",
    "\n",
    "# ✅ Function for Preprocessing Button\n",
    "def preprocess_image(image):\n",
    "    _, processed_image = preprocess_pipeline(image)\n",
    "    return processed_image\n",
    "\n",
    "# GUI\n",
    "def gui():\n",
    "    with gr.Blocks() as demo:\n",
    "        gr.Markdown(\"## Image Classification Demo\")\n",
    "\n",
    "        with gr.Row():\n",
    "            with gr.Column():\n",
    "                image_input = gr.Image(label=\"Upload a Photo\", type=\"numpy\")\n",
    "                preprocess_button = gr.Button(\"Preprocess\")  # ✅ Added Preprocessing Button\n",
    "                preprocess_output = gr.Image(label=\"Preprocessed Image Preview\")  # ✅ Preprocessing Output\n",
    "            with gr.Column():\n",
    "                model_dropdown = gr.Dropdown(choices=list(models.keys()), label=\"Select Model\", value=\"Random Forest\")\n",
    "                classify_button = gr.Button(\"Classify\")\n",
    "                prediction_output = gr.Textbox(label=\"Predicted Label\", interactive=False)\n",
    "\n",
    "        # ✅ Preprocessing Button Click\n",
    "        preprocess_button.click(preprocess_image, inputs=image_input, outputs=preprocess_output)\n",
    "\n",
    "        # ✅ Classification Button Click\n",
    "        classify_button.click(classify_image, inputs=[image_input, model_dropdown], outputs=[preprocess_output, prediction_output])\n",
    "\n",
    "    demo.launch()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    gui()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7863\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Marwan Shamsan\\AppData\\Local\\Temp\\ipykernel_5684\\2946655941.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  reshaped_array = (reshaped_array - reshaped_array.min()) / (reshaped_array.max() - reshaped_array.min())  # Normalize\n",
      "C:\\Users\\Marwan Shamsan\\AppData\\Local\\Temp\\ipykernel_5684\\2946655941.py:28: RuntimeWarning: invalid value encountered in cast\n",
      "  reshaped_array = (reshaped_array * 255).astype(np.uint8)  # Convert to 8-bit image\n",
      "Exception in callback _ProactorBasePipeTransport._call_connection_lost(None)\n",
      "handle: <Handle _ProactorBasePipeTransport._call_connection_lost(None)>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Marwan Shamsan\\anaconda3\\Lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\Users\\Marwan Shamsan\\anaconda3\\Lib\\asyncio\\proactor_events.py\", line 165, in _call_connection_lost\n",
      "    self._sock.shutdown(socket.SHUT_RDWR)\n",
      "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grayscale Image Min: 0.0, Max: 1.0\n",
      "ADF Filtered Min: 0, Max: 255\n",
      "Skull Stripped Min: 0, Max: 255\n",
      "Tophat Filtered Min: 0, Max: 255\n",
      "Contrast Enhanced Min: 0, Max: 255\n",
      "Binary Image Min: False, Max: True\n",
      "Segmented Image Min: 0, Max: 2\n",
      "Opened Image Post Min: 0, Max: 0\n",
      "Resized Opened Image Min: 0, Max: 0\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import numpy as np\n",
    "import cupy as cp\n",
    "import cv2\n",
    "from skimage.util import img_as_ubyte, img_as_float\n",
    "from skimage import morphology, filters, segmentation, exposure, feature\n",
    "from scipy.ndimage import convolve, gaussian_gradient_magnitude, distance_transform_edt\n",
    "from scipy.ndimage import label as nd_label\n",
    "from skimage.color import rgb2gray\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from joblib import load\n",
    "from skimage import transform\n",
    "\n",
    "# Load models\n",
    "models = {\n",
    "    \"Random Forest\": r\"C:\\Marwan APU\\Sem-2\\PR\\brine\\new_pkl\\best_random_forest_model.pkl\",\n",
    "    \"KNN\": r\"C:\\Marwan APU\\Sem-2\\PR\\brine\\new_pkl\\best_KNN_model.pkl\",\n",
    "    \"Decision Tree\": r\"C:\\Marwan APU\\Sem-2\\PR\\brine\\new_pkl\\Decision_tree_model.pkl\",\n",
    "    \"Gaussian NB\": r\"C:\\Marwan APU\\Sem-2\\PR\\brine\\new_pkl\\GaussianNB_model.pkl\",\n",
    "    \"Logistic Regression\": r\"C:\\Marwan APU\\Sem-2\\PR\\brine\\new_pkl\\logistic_regression_model.pkl\",\n",
    "    \"SVM\": r\"C:\\Marwan APU\\Sem-2\\PR\\brine\\new_pkl\\svm_model.pkl\",\n",
    "}\n",
    "\n",
    "loaded_models = {model_name: load(model_path) for model_name, model_path in models.items()}\n",
    "\n",
    "# Step 1: Anisotropic Diffusion Filter (ADF)\n",
    "def anisotropic_diffusion_filter(image, alpha=0.1, beta=0.1, iterations=3):\n",
    "    image = img_as_float(image.copy())\n",
    "    for _ in range(iterations):\n",
    "        gradient_magnitude = gaussian_gradient_magnitude(image, sigma=1)\n",
    "        c = 1.0 / (1.0 + (gradient_magnitude / beta) ** 2)\n",
    "        diff_north = convolve(image, np.array([[0, 1, 0], [0, -1, 0], [0, 0, 0]]))\n",
    "        diff_south = convolve(image, np.array([[0, 0, 0], [0, -1, 0], [0, 1, 0]]))\n",
    "        diff_east = convolve(image, np.array([[0, 0, 0], [0, -1, 1], [0, 0, 0]]))\n",
    "        diff_west = convolve(image, np.array([[0, 0, 0], [1, -1, 0], [0, 0, 0]]))\n",
    "        image += alpha * (c * diff_north + c * diff_south + c * diff_east + c * diff_west)\n",
    "    return img_as_ubyte(image)\n",
    "\n",
    "# Step 2: Skull Stripping\n",
    "def skull_stripping(image, se_closing=None, se_erosion=None, skull_remove_area=2000):\n",
    "    if se_closing is None:\n",
    "        se_closing = morphology.disk(15)\n",
    "    if se_erosion is None:\n",
    "        se_erosion = morphology.disk(30)\n",
    "    threshold_value = filters.threshold_otsu(image)\n",
    "    binary_image = image > threshold_value\n",
    "    filled_image = morphology.closing(binary_image, se_closing)\n",
    "    filled_image = morphology.remove_small_holes(filled_image, area_threshold=skull_remove_area)\n",
    "    eroded_image = morphology.erosion(filled_image, se_erosion)\n",
    "    return np.where(eroded_image, image, 0)\n",
    "\n",
    "# Step 3: Top-Hat Filtering\n",
    "def top_hat_filtering(image, disk_size=30):\n",
    "    footprint = morphology.disk(disk_size)\n",
    "    return morphology.white_tophat(image, footprint)\n",
    "\n",
    "# Step 4: Contrast Enhancement\n",
    "def contrast_enhancement(image):\n",
    "    contrasted_image = exposure.equalize_hist(image)\n",
    "    contrasted_image = (contrasted_image - np.min(contrasted_image)) / (np.max(contrasted_image) - np.min(contrasted_image))\n",
    "    return img_as_ubyte(contrasted_image)\n",
    "\n",
    "# Step 5: Binary Segmentation\n",
    "def get_binary(image, thresh=None):\n",
    "    if thresh is None:\n",
    "        thresh = filters.threshold_otsu(image)\n",
    "    binary_image = image > thresh\n",
    "    return binary_image, thresh\n",
    "\n",
    "# Step 6: Watershed Segmentation\n",
    "def watershed_segmentation(image, se_peak_local=np.ones((3, 3))):\n",
    "    distance = distance_transform_edt(image)\n",
    "    local_maxi = feature.peak_local_max(distance, labels=image, footprint=se_peak_local, exclude_border=False)\n",
    "    local_maxi_mask = np.zeros_like(image, dtype=bool)\n",
    "    local_maxi_mask[tuple(local_maxi.T)] = True\n",
    "    markers = nd_label(local_maxi_mask)[0]\n",
    "    segmented_image = segmentation.watershed(-distance, markers, mask=image)\n",
    "    nbr_labels = np.max(segmented_image)\n",
    "    return segmented_image, nbr_labels\n",
    "\n",
    "# Step 7: Morphological Operations\n",
    "def apply_morphological_operations(segmented_image):\n",
    "    if not isinstance(segmented_image, np.ndarray) or segmented_image.ndim != 2:\n",
    "        return None, None\n",
    "    closed_image = morphology.closing(segmented_image, morphology.disk(6))\n",
    "    opened_image = morphology.opening(closed_image, morphology.disk(5))\n",
    "    return closed_image, opened_image\n",
    "\n",
    "# Full preprocessing pipeline\n",
    "def preprocess_pipeline(image):\n",
    "    try:\n",
    "        grayscale_image = rgb2gray(image)\n",
    "        print(f\"Grayscale Image Min: {grayscale_image.min()}, Max: {grayscale_image.max()}\")\n",
    "\n",
    "        adf_filtered_image = anisotropic_diffusion_filter(grayscale_image)\n",
    "        print(f\"ADF Filtered Min: {adf_filtered_image.min()}, Max: {adf_filtered_image.max()}\")\n",
    "\n",
    "        skull_stripped_image = skull_stripping(adf_filtered_image)\n",
    "        print(f\"Skull Stripped Min: {skull_stripped_image.min()}, Max: {skull_stripped_image.max()}\")\n",
    "\n",
    "        tophat_image = top_hat_filtering(skull_stripped_image)\n",
    "        print(f\"Tophat Filtered Min: {tophat_image.min()}, Max: {tophat_image.max()}\")\n",
    "\n",
    "        contrasted_image = contrast_enhancement(tophat_image)\n",
    "        print(f\"Contrast Enhanced Min: {contrasted_image.min()}, Max: {contrasted_image.max()}\")\n",
    "\n",
    "        binary_image, _ = get_binary(contrasted_image, thresh=230)\n",
    "        print(f\"Binary Image Min: {binary_image.min()}, Max: {binary_image.max()}\")\n",
    "\n",
    "        segmented_image, _ = watershed_segmentation(binary_image, morphology.disk(10))\n",
    "        print(f\"Segmented Image Min: {segmented_image.min()}, Max: {segmented_image.max()}\")\n",
    "\n",
    "        closed_image_post, opened_image_post = apply_morphological_operations(segmented_image)\n",
    "        print(f\"Opened Image Post Min: {opened_image_post.min()}, Max: {opened_image_post.max()}\")\n",
    "\n",
    "        # Resize to 256x256\n",
    "        resized_opened_image = transform.resize(opened_image_post, (256, 256))\n",
    "        resized_opened_image = (resized_opened_image * 255).astype(np.uint8)\n",
    "        print(f\"Resized Opened Image Min: {resized_opened_image.min()}, Max: {resized_opened_image.max()}\")\n",
    "\n",
    "        # Flatten and scale\n",
    "        flattened_image = resized_opened_image.flatten().reshape(1, -1)\n",
    "        scaler = MinMaxScaler()\n",
    "        scaled_features = scaler.fit_transform(flattened_image)\n",
    "\n",
    "        return scaled_features, resized_opened_image\n",
    "    except Exception as e:\n",
    "        print(f\"Error in preprocessing pipeline: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "# Classification Function\n",
    "def classify_image(image, model_name):\n",
    "    try:\n",
    "        scaled_features, opened_image = preprocess_pipeline(image)\n",
    "        model = loaded_models[model_name]\n",
    "\n",
    "        # Dynamically match feature size\n",
    "        expected_size = model.n_features_in_\n",
    "        if scaled_features.shape[1] != expected_size:\n",
    "            print(f\"Resizing from {scaled_features.shape[1]} to {expected_size}\")\n",
    "            scaled_features = np.resize(scaled_features, (1, expected_size))\n",
    "\n",
    "        prediction = model.predict(scaled_features)\n",
    "        return opened_image, f\"Predicted Label: {prediction[0]}\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error in classification: {e}\")\n",
    "        return None, \"Error\"\n",
    "\n",
    "# Preprocessing Button Function\n",
    "def preprocess_image(image):\n",
    "    _, processed_image = preprocess_pipeline(image)\n",
    "    return processed_image\n",
    "\n",
    "# GUI\n",
    "def gui():\n",
    "    with gr.Blocks() as demo:\n",
    "        gr.Markdown(\"## Image Classification Demo\")\n",
    "\n",
    "        with gr.Row():\n",
    "            with gr.Column():\n",
    "                image_input = gr.Image(label=\"Upload a Photo\", type=\"numpy\")\n",
    "                preprocess_button = gr.Button(\"Preprocess\")\n",
    "                preprocess_output = gr.Image(label=\"Preprocessed Image Preview\")\n",
    "            with gr.Column():\n",
    "                model_dropdown = gr.Dropdown(choices=list(models.keys()), label=\"Select Model\", value=\"Random Forest\")\n",
    "                classify_button = gr.Button(\"Classify\")\n",
    "                prediction_output = gr.Textbox(label=\"Predicted Label\", interactive=False)\n",
    "\n",
    "        preprocess_button.click(preprocess_image, inputs=image_input, outputs=preprocess_output)\n",
    "        classify_button.click(classify_image, inputs=[image_input, model_dropdown], outputs=[preprocess_output, prediction_output])\n",
    "\n",
    "    demo.launch()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    gui()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing pipeline loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# Define the missing class before loading the pickle file\n",
    "class ImagePreprocessor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self  # No training needed\n",
    "\n",
    "    def transform(self, X):\n",
    "        processed_images = []\n",
    "        for image in X:\n",
    "            try:\n",
    "                # Apply the full pipeline to each image\n",
    "                adf_filtered_image = anisotropic_diffusion_filter(image)\n",
    "                skull_stripped_image = skull_stripping(adf_filtered_image)\n",
    "                tophat_image = top_hat_filtering(skull_stripped_image)\n",
    "                contrasted_image = contrast_enhancement(tophat_image)\n",
    "                binary_image, _ = get_binary(contrasted_image, thresh=230)\n",
    "                segmented_image, _ = watershed_segmentation(binary_image, morphology.disk(10))\n",
    "                _, opened_image = apply_morphological_operations(segmented_image)\n",
    "\n",
    "                # Resize to 256x256\n",
    "                resized_opened_image = transform.resize(opened_image, (256, 256), anti_aliasing=True)\n",
    "                if resized_opened_image.max() > 0:\n",
    "                    resized_opened_image = (resized_opened_image / resized_opened_image.max()) * 255\n",
    "                resized_opened_image = resized_opened_image.astype(np.uint8)\n",
    "\n",
    "                # Flatten the image\n",
    "                flattened_image = resized_opened_image.flatten().reshape(1, -1)\n",
    "                \n",
    "                processed_images.append(flattened_image)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing image: {e}\")\n",
    "                processed_images.append(None)\n",
    "\n",
    "        return np.vstack(processed_images)  # Stack all images together\n",
    "\n",
    "# ✅ Now Load the Preprocessing Pipeline\n",
    "import joblib\n",
    "preprocessor = joblib.load(r\"C:\\Marwan APU\\Sem-2\\PR\\brine\\new_pkl\\preprocessing_pipeline.pkl\")\n",
    "print(\"Preprocessing pipeline loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7889\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7889/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import numpy as np\n",
    "import joblib\n",
    "from joblib import load\n",
    "from skimage.color import rgb2gray\n",
    "\n",
    "# Load preprocessing pipeline\n",
    "preprocessing_pipeline_path = r\"C:\\Marwan APU\\Sem-2\\PR\\brine\\new_pkl\\preprocessing_pipeline.pkl\"\n",
    "preprocessor = joblib.load(preprocessing_pipeline_path)\n",
    "\n",
    "# Load trained models\n",
    "models = {\n",
    "    \"Random Forest\": r\"C:\\Marwan APU\\Sem-2\\PR\\brine\\new_pkl\\best_random_forest_model.pkl\",\n",
    "    \"KNN\": r\"C:\\Marwan APU\\Sem-2\\PR\\brine\\new_pkl\\best_KNN_model.pkl\",\n",
    "    \"Decision Tree\": r\"C:\\Marwan APU\\Sem-2\\PR\\brine\\new_pkl\\Decision_tree_model.pkl\",\n",
    "    \"Gaussian NB\": r\"C:\\Marwan APU\\Sem-2\\PR\\brine\\new_pkl\\GaussianNB_model.pkl\",\n",
    "    \"Logistic Regression\": r\"C:\\Marwan APU\\Sem-2\\PR\\brine\\new_pkl\\logistic_regression_model.pkl\",\n",
    "    \"SVM\": r\"C:\\Marwan APU\\Sem-2\\PR\\brine\\new_pkl\\svm_model.pkl\",\n",
    "}\n",
    "\n",
    "loaded_models = {model_name: load(model_path) for model_name, model_path in models.items()}\n",
    "\n",
    "# ✅ Function to preprocess image using the saved pipeline\n",
    "def preprocess_image(image):\n",
    "    try:\n",
    "        grayscale_image = rgb2gray(image)  # Convert to grayscale if needed\n",
    "        processed_features = preprocessor.transform([grayscale_image])  # Apply the saved pipeline\n",
    "        return processed_features.reshape(256, 256)  # Return as an image for preview\n",
    "    except Exception as e:\n",
    "        print(f\"Error in preprocessing: {e}\")\n",
    "        return None\n",
    "\n",
    "# ✅ Classification Function Using Preprocessed Image\n",
    "def classify_image(image, model_name):\n",
    "    try:\n",
    "        processed_features = preprocess_image(image)\n",
    "        if processed_features is None:\n",
    "            return None, \"Error in preprocessing\"\n",
    "\n",
    "        model = loaded_models[model_name]\n",
    "\n",
    "        # Ensure feature size matches model expectations\n",
    "        expected_size = model.n_features_in_\n",
    "        processed_features = processed_features.flatten().reshape(1, -1)  # Flatten before resizing\n",
    "        if processed_features.shape[1] != expected_size:\n",
    "            processed_features = np.resize(processed_features, (1, expected_size))\n",
    "\n",
    "        prediction = model.predict(processed_features)\n",
    "        return image, f\"Predicted Label: {prediction[0]}\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error in classification: {e}\")\n",
    "        return None, \"Error\"\n",
    "\n",
    "# ✅ Gradio GUI\n",
    "def gui():\n",
    "    with gr.Blocks() as demo:\n",
    "        gr.Markdown(\"## Image Classification Demo\")\n",
    "\n",
    "        with gr.Row():\n",
    "            with gr.Column():\n",
    "                image_input = gr.Image(label=\"Upload a Photo\", type=\"numpy\")\n",
    "                preprocess_button = gr.Button(\"Preprocess\")\n",
    "                preprocess_output = gr.Image(label=\"Preprocessed Image Preview\")\n",
    "            with gr.Column():\n",
    "                model_dropdown = gr.Dropdown(choices=list(models.keys()), label=\"Select Model\", value=\"Random Forest\")\n",
    "                classify_button = gr.Button(\"Classify\")\n",
    "                prediction_output = gr.Textbox(label=\"Predicted Label\", interactive=False)\n",
    "\n",
    "        preprocess_button.click(preprocess_image, inputs=image_input, outputs=preprocess_output)\n",
    "        classify_button.click(classify_image, inputs=[image_input, model_dropdown], outputs=[preprocess_output, prediction_output])\n",
    "\n",
    "    demo.launch()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    gui()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7890\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7890/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import numpy as np\n",
    "import joblib\n",
    "from joblib import load\n",
    "from skimage.color import rgb2gray\n",
    "\n",
    "# Load preprocessing pipeline\n",
    "preprocessing_pipeline_path = r\"C:\\Marwan APU\\Sem-2\\PR\\brine\\new_pkl\\preprocessing_pipeline.pkl\"\n",
    "preprocessor = joblib.load(preprocessing_pipeline_path)\n",
    "\n",
    "# Load trained models\n",
    "models = {\n",
    "    \"Random Forest\": r\"C:\\Marwan APU\\Sem-2\\PR\\brine\\new_pkl\\best_random_forest_model.pkl\",\n",
    "    \"KNN\": r\"C:\\Marwan APU\\Sem-2\\PR\\brine\\new_pkl\\best_KNN_model.pkl\",\n",
    "    \"Decision Tree\": r\"C:\\Marwan APU\\Sem-2\\PR\\brine\\new_pkl\\Decision_tree_model.pkl\",\n",
    "    \"Gaussian NB\": r\"C:\\Marwan APU\\Sem-2\\PR\\brine\\new_pkl\\GaussianNB_model.pkl\",\n",
    "    \"Logistic Regression\": r\"C:\\Marwan APU\\Sem-2\\PR\\brine\\new_pkl\\logistic_regression_model.pkl\",\n",
    "    \"SVM\": r\"C:\\Marwan APU\\Sem-2\\PR\\brine\\new_pkl\\svm_model.pkl\",\n",
    "}\n",
    "\n",
    "loaded_models = {model_name: load(model_path) for model_name, model_path in models.items()}\n",
    "\n",
    "# ✅ Function to preprocess image using the saved pipeline\n",
    "def preprocess_image(image):\n",
    "    try:\n",
    "        grayscale_image = rgb2gray(image)  # Convert to grayscale if needed\n",
    "        processed_features = preprocessor.transform([grayscale_image])  # Apply the saved pipeline\n",
    "        preprocessed_image = processed_features.reshape(256, 256)  # Reshape for image preview\n",
    "        return image, preprocessed_image\n",
    "    except Exception as e:\n",
    "        print(f\"Error in preprocessing: {e}\")\n",
    "        return image, None\n",
    "\n",
    "# ✅ Classification Function Using Preprocessed Image\n",
    "def classify_image(image, model_name):\n",
    "    try:\n",
    "        grayscale_image = rgb2gray(image)  # Ensure grayscale conversion\n",
    "        processed_features = preprocessor.transform([grayscale_image])  # Apply preprocessing\n",
    "\n",
    "        if processed_features is None:\n",
    "            return image, None, \"Error in preprocessing\"\n",
    "\n",
    "        model = loaded_models[model_name]\n",
    "\n",
    "        # Ensure feature size matches model expectations\n",
    "        expected_size = model.n_features_in_\n",
    "        processed_features = processed_features.flatten().reshape(1, -1)  # Flatten before resizing\n",
    "        if processed_features.shape[1] != expected_size:\n",
    "            processed_features = np.resize(processed_features, (1, expected_size))\n",
    "\n",
    "        prediction = model.predict(processed_features)\n",
    "        preprocessed_image = processed_features.reshape(256, 256)  # Preprocessed image for display\n",
    "        return image, preprocessed_image, f\"Predicted Label: {prediction[0]}\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error in classification: {e}\")\n",
    "        return image, None, \"Error\"\n",
    "\n",
    "# ✅ Gradio GUI\n",
    "def gui():\n",
    "    with gr.Blocks() as demo:\n",
    "        gr.Markdown(\"## Image Classification Demo\")\n",
    "\n",
    "        with gr.Row():\n",
    "            with gr.Column():\n",
    "                image_input = gr.Image(label=\"Upload a Photo\", type=\"numpy\", interactive=True)\n",
    "                preprocess_button = gr.Button(\"Preprocess\")\n",
    "                preprocess_output = gr.Image(label=\"Preprocessed Image Preview\")\n",
    "            with gr.Column():\n",
    "                model_dropdown = gr.Dropdown(choices=list(models.keys()), label=\"Select Model\", value=\"Random Forest\")\n",
    "                classify_button = gr.Button(\"Classify\")\n",
    "                prediction_output = gr.Textbox(label=\"Predicted Label\", interactive=False)\n",
    "\n",
    "        # Button actions\n",
    "        preprocess_button.click(preprocess_image, inputs=image_input, outputs=[image_input, preprocess_output])\n",
    "        classify_button.click(classify_image, inputs=[image_input, model_dropdown], outputs=[image_input, preprocess_output, prediction_output])\n",
    "\n",
    "    demo.launch()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    gui()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7891\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7891/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import numpy as np\n",
    "import joblib\n",
    "from joblib import load\n",
    "from skimage.color import rgb2gray\n",
    "\n",
    "# Load preprocessing pipeline\n",
    "preprocessing_pipeline_path = r\"C:\\Marwan APU\\Sem-2\\PR\\brine\\new_pkl\\preprocessing_pipeline.pkl\"\n",
    "preprocessor = joblib.load(preprocessing_pipeline_path)\n",
    "\n",
    "# Load trained models\n",
    "models = {\n",
    "    \"Random Forest\": r\"C:\\Marwan APU\\Sem-2\\PR\\brine\\new_pkl\\best_random_forest_model.pkl\",\n",
    "    \"KNN\": r\"C:\\Marwan APU\\Sem-2\\PR\\brine\\new_pkl\\best_KNN_model.pkl\",\n",
    "    \"Decision Tree\": r\"C:\\Marwan APU\\Sem-2\\PR\\brine\\new_pkl\\Decision_tree_model.pkl\",\n",
    "    \"Gaussian NB\": r\"C:\\Marwan APU\\Sem-2\\PR\\brine\\new_pkl\\GaussianNB_model.pkl\",\n",
    "    \"Logistic Regression\": r\"C:\\Marwan APU\\Sem-2\\PR\\brine\\new_pkl\\logistic_regression_model.pkl\",\n",
    "    \"SVM\": r\"C:\\Marwan APU\\Sem-2\\PR\\brine\\new_pkl\\svm_model.pkl\",\n",
    "}\n",
    "\n",
    "loaded_models = {model_name: load(model_path) for model_name, model_path in models.items()}\n",
    "\n",
    "# ✅ Function to dynamically reshape a flattened array\n",
    "def dynamic_reshape(flattened_array):\n",
    "    \"\"\"Dynamically reshapes a flattened array into a square or near-square shape.\"\"\"\n",
    "    length = flattened_array.shape[0]\n",
    "    side = int(np.sqrt(length))  # Find the largest square shape possible\n",
    "    reshaped_array = flattened_array[:side * side].reshape(side, side)  # Crop excess and reshape\n",
    "    return reshaped_array\n",
    "\n",
    "# ✅ Function to preprocess image using the saved pipeline\n",
    "def preprocess_image(image):\n",
    "    try:\n",
    "        grayscale_image = rgb2gray(image)  # Convert to grayscale if needed\n",
    "        processed_features = preprocessor.transform([grayscale_image])  # Apply the saved pipeline\n",
    "        preprocessed_image = dynamic_reshape(processed_features.flatten())  # Dynamically reshape\n",
    "        return image, preprocessed_image\n",
    "    except Exception as e:\n",
    "        print(f\"Error in preprocessing: {e}\")\n",
    "        return image, None\n",
    "\n",
    "# ✅ Classification Function Using Preprocessed Image\n",
    "def classify_image(image, model_name):\n",
    "    try:\n",
    "        grayscale_image = rgb2gray(image)  # Ensure grayscale conversion\n",
    "        processed_features = preprocessor.transform([grayscale_image])  # Apply preprocessing\n",
    "\n",
    "        if processed_features is None:\n",
    "            return image, None, \"Error in preprocessing\"\n",
    "\n",
    "        model = loaded_models[model_name]\n",
    "\n",
    "        # Ensure feature size matches model expectations\n",
    "        expected_size = model.n_features_in_\n",
    "        processed_features = processed_features.flatten().reshape(1, -1)  # Flatten before resizing\n",
    "        if processed_features.shape[1] != expected_size:\n",
    "            processed_features = np.resize(processed_features, (1, expected_size))\n",
    "\n",
    "        prediction = model.predict(processed_features)\n",
    "        preprocessed_image = dynamic_reshape(processed_features.flatten())  # Dynamically reshape\n",
    "        return image, preprocessed_image, f\"Predicted Label: {prediction[0]}\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error in classification: {e}\")\n",
    "        return image, None, \"Error\"\n",
    "\n",
    "# ✅ Gradio GUI\n",
    "def gui():\n",
    "    with gr.Blocks() as demo:\n",
    "        gr.Markdown(\"## Image Classification Demo\")\n",
    "\n",
    "        with gr.Row():\n",
    "            with gr.Column():\n",
    "                image_input = gr.Image(label=\"Upload a Photo\", type=\"numpy\", interactive=True)\n",
    "                preprocess_button = gr.Button(\"Preprocess\")\n",
    "                preprocess_output = gr.Image(label=\"Preprocessed Image Preview\")\n",
    "            with gr.Column():\n",
    "                model_dropdown = gr.Dropdown(choices=list(models.keys()), label=\"Select Model\", value=\"Random Forest\")\n",
    "                classify_button = gr.Button(\"Classify\")\n",
    "                prediction_output = gr.Textbox(label=\"Predicted Label\", interactive=False)\n",
    "\n",
    "        # Button actions\n",
    "        preprocess_button.click(preprocess_image, inputs=image_input, outputs=[image_input, preprocess_output])\n",
    "        classify_button.click(classify_image, inputs=[image_input, model_dropdown], outputs=[image_input, preprocess_output, prediction_output])\n",
    "\n",
    "    demo.launch()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    gui()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7892\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7892/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import numpy as np\n",
    "import joblib\n",
    "from joblib import load\n",
    "from skimage.color import rgb2gray\n",
    "\n",
    "# Load preprocessing pipeline\n",
    "preprocessing_pipeline_path = r\"C:\\Marwan APU\\Sem-2\\PR\\brine\\new_pkl\\preprocessing_pipeline.pkl\"\n",
    "preprocessor = joblib.load(preprocessing_pipeline_path)\n",
    "\n",
    "# Load trained models\n",
    "models = {\n",
    "    \"Random Forest\": r\"C:\\Marwan APU\\Sem-2\\PR\\brine\\new_pkl\\best_random_forest_model.pkl\",\n",
    "    \"KNN\": r\"C:\\Marwan APU\\Sem-2\\PR\\brine\\new_pkl\\best_KNN_model.pkl\",\n",
    "    \"Decision Tree\": r\"C:\\Marwan APU\\Sem-2\\PR\\brine\\new_pkl\\Decision_tree_model.pkl\",\n",
    "    \"Gaussian NB\": r\"C:\\Marwan APU\\Sem-2\\PR\\brine\\new_pkl\\GaussianNB_model.pkl\",\n",
    "    \"Logistic Regression\": r\"C:\\Marwan APU\\Sem-2\\PR\\brine\\new_pkl\\logistic_regression_model.pkl\",\n",
    "    \"SVM\": r\"C:\\Marwan APU\\Sem-2\\PR\\brine\\new_pkl\\svm_model.pkl\",\n",
    "}\n",
    "\n",
    "loaded_models = {model_name: load(model_path) for model_name, model_path in models.items()}\n",
    "\n",
    "# ✅ Function to dynamically resize an image for visualization\n",
    "def resize_for_visualization(flattened_array, target_size=(256, 256)):\n",
    "    \"\"\"Resizes the flattened array to the target size for visualization.\"\"\"\n",
    "    reshaped_array = flattened_array[: np.prod(target_size)].reshape(target_size)  # Crop and reshape\n",
    "    reshaped_array = (reshaped_array - reshaped_array.min()) / (reshaped_array.max() - reshaped_array.min())  # Normalize\n",
    "    reshaped_array = (reshaped_array * 255).astype(np.uint8)  # Convert to 8-bit image\n",
    "    return reshaped_array\n",
    "\n",
    "# ✅ Function to preprocess image using the saved pipeline\n",
    "def preprocess_image(image):\n",
    "    try:\n",
    "        grayscale_image = rgb2gray(image)  # Convert to grayscale if needed\n",
    "        processed_features = preprocessor.transform([grayscale_image])  # Apply the saved pipeline\n",
    "        visualization_image = resize_for_visualization(processed_features.flatten())  # Resize for preview\n",
    "        return image, visualization_image\n",
    "    except Exception as e:\n",
    "        print(f\"Error in preprocessing: {e}\")\n",
    "        return image, None\n",
    "\n",
    "# ✅ Classification Function Using Preprocessed Image\n",
    "def classify_image(image, model_name):\n",
    "    try:\n",
    "        grayscale_image = rgb2gray(image)  # Ensure grayscale conversion\n",
    "        processed_features = preprocessor.transform([grayscale_image])  # Apply preprocessing\n",
    "\n",
    "        if processed_features is None:\n",
    "            return image, None, \"Error in preprocessing\"\n",
    "\n",
    "        model = loaded_models[model_name]\n",
    "\n",
    "        # Ensure feature size matches model expectations\n",
    "        expected_size = model.n_features_in_\n",
    "        flattened_features = processed_features.flatten().reshape(1, -1)  # Flatten before resizing\n",
    "        if flattened_features.shape[1] != expected_size:\n",
    "            flattened_features = np.resize(flattened_features, (1, expected_size))\n",
    "\n",
    "        prediction = model.predict(flattened_features)\n",
    "        visualization_image = resize_for_visualization(processed_features.flatten())  # Resize for preview\n",
    "        return image, visualization_image, f\"Predicted Label: {prediction[0]}\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error in classification: {e}\")\n",
    "        return image, None, \"Error\"\n",
    "\n",
    "# ✅ Gradio GUI\n",
    "def gui():\n",
    "    with gr.Blocks() as demo:\n",
    "        gr.Markdown(\"## Image Classification Demo\")\n",
    "\n",
    "        with gr.Row():\n",
    "            with gr.Column():\n",
    "                image_input = gr.Image(label=\"Upload a Photo\", type=\"numpy\", interactive=True)\n",
    "                preprocess_button = gr.Button(\"Preprocess\")\n",
    "                preprocess_output = gr.Image(label=\"Preprocessed Image Preview\")\n",
    "            with gr.Column():\n",
    "                model_dropdown = gr.Dropdown(choices=list(models.keys()), label=\"Select Model\", value=\"Random Forest\")\n",
    "                classify_button = gr.Button(\"Classify\")\n",
    "                prediction_output = gr.Textbox(label=\"Predicted Label\", interactive=False)\n",
    "\n",
    "        # Button actions\n",
    "        preprocess_button.click(preprocess_image, inputs=image_input, outputs=[image_input, preprocess_output])\n",
    "        classify_button.click(classify_image, inputs=[image_input, model_dropdown], outputs=[image_input, preprocess_output, prediction_output])\n",
    "\n",
    "    demo.launch()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    gui()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import numpy as np\n",
    "import cupy as cp\n",
    "import cv2\n",
    "from skimage.util import img_as_ubyte, img_as_float\n",
    "from skimage import morphology, filters, segmentation, exposure, feature\n",
    "from scipy.ndimage import convolve, gaussian_gradient_magnitude, distance_transform_edt\n",
    "from scipy.ndimage import label as nd_label\n",
    "from skimage.color import rgb2gray\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from joblib import load\n",
    "from skimage import transform\n",
    "\n",
    "# Load models\n",
    "models = {\n",
    "    \"Random Forest\": r\"C:\\Marwan APU\\Sem-2\\PR\\brine\\new_pkl\\best_random_forest_model.pkl\",\n",
    "    \"KNN\": r\"C:\\Marwan APU\\Sem-2\\PR\\brine\\new_pkl\\best_KNN_model.pkl\",\n",
    "    \"Decision Tree\": r\"C:\\Marwan APU\\Sem-2\\PR\\brine\\new_pkl\\Decision_tree_model.pkl\",\n",
    "    \"Gaussian NB\": r\"C:\\Marwan APU\\Sem-2\\PR\\brine\\new_pkl\\GaussianNB_model.pkl\",\n",
    "    \"Logistic Regression\": r\"C:\\Marwan APU\\Sem-2\\PR\\brine\\new_pkl\\logistic_regression_model.pkl\",\n",
    "    \"SVM\": r\"C:\\Marwan APU\\Sem-2\\PR\\brine\\new_pkl\\svm_model.pkl\",\n",
    "}\n",
    "\n",
    "loaded_models = {model_name: load(model_path) for model_name, model_path in models.items()}\n",
    "\n",
    "# Step 1: Anisotropic Diffusion Filter (ADF)\n",
    "def anisotropic_diffusion_filter(image, alpha=0.1, beta=0.1, iterations=3):\n",
    "    image = img_as_float(image.copy())\n",
    "    for _ in range(iterations):\n",
    "        gradient_magnitude = gaussian_gradient_magnitude(image, sigma=1)\n",
    "        c = 1.0 / (1.0 + (gradient_magnitude / beta) ** 2)\n",
    "        diff_north = convolve(image, np.array([[0, 1, 0], [0, -1, 0], [0, 0, 0]]))\n",
    "        diff_south = convolve(image, np.array([[0, 0, 0], [0, -1, 0], [0, 1, 0]]))\n",
    "        diff_east = convolve(image, np.array([[0, 0, 0], [0, -1, 1], [0, 0, 0]]))\n",
    "        diff_west = convolve(image, np.array([[0, 0, 0], [1, -1, 0], [0, 0, 0]]))\n",
    "        image += alpha * (c * diff_north + c * diff_south + c * diff_east + c * diff_west)\n",
    "    return img_as_ubyte(image)\n",
    "\n",
    "# Step 2: Skull Stripping\n",
    "def skull_stripping(image, se_closing=None, se_erosion=None, skull_remove_area=2000):\n",
    "    if se_closing is None:\n",
    "        se_closing = morphology.disk(15)\n",
    "    if se_erosion is None:\n",
    "        se_erosion = morphology.disk(30)\n",
    "    threshold_value = filters.threshold_otsu(image)\n",
    "    binary_image = image > threshold_value\n",
    "    filled_image = morphology.closing(binary_image, se_closing)\n",
    "    filled_image = morphology.remove_small_holes(filled_image, area_threshold=skull_remove_area)\n",
    "    eroded_image = morphology.erosion(filled_image, se_erosion)\n",
    "    return np.where(eroded_image, image, 0)\n",
    "\n",
    "# Step 3: Top-Hat Filtering\n",
    "def top_hat_filtering(image, disk_size=30):\n",
    "    footprint = morphology.disk(disk_size)\n",
    "    return morphology.white_tophat(image, footprint)\n",
    "\n",
    "# Step 4: Contrast Enhancement\n",
    "def contrast_enhancement(image):\n",
    "    contrasted_image = exposure.equalize_hist(image)\n",
    "    contrasted_image = (contrasted_image - np.min(contrasted_image)) / (np.max(contrasted_image) - np.min(contrasted_image))\n",
    "    return img_as_ubyte(contrasted_image)\n",
    "\n",
    "# Step 5: Binary Segmentation\n",
    "def get_binary(image, thresh=None):\n",
    "    if thresh is None:\n",
    "        thresh = filters.threshold_otsu(image)\n",
    "    binary_image = image > thresh\n",
    "    return binary_image, thresh\n",
    "\n",
    "# Step 6: Watershed Segmentation\n",
    "def watershed_segmentation(image, se_peak_local=np.ones((3, 3))):\n",
    "    distance = distance_transform_edt(image)\n",
    "    local_maxi = feature.peak_local_max(distance, labels=image, footprint=se_peak_local, exclude_border=False)\n",
    "    local_maxi_mask = np.zeros_like(image, dtype=bool)\n",
    "    local_maxi_mask[tuple(local_maxi.T)] = True\n",
    "    markers = nd_label(local_maxi_mask)[0]\n",
    "    segmented_image = segmentation.watershed(-distance, markers, mask=image)\n",
    "    nbr_labels = np.max(segmented_image)\n",
    "    return segmented_image, nbr_labels\n",
    "\n",
    "# Step 7: Morphological Operations\n",
    "def apply_morphological_operations(segmented_image):\n",
    "    if not isinstance(segmented_image, np.ndarray) or segmented_image.ndim != 2:\n",
    "        return None, None\n",
    "    closed_image = morphology.closing(segmented_image, morphology.disk(6))\n",
    "    opened_image = morphology.opening(closed_image, morphology.disk(5))\n",
    "    return closed_image, opened_image\n",
    "\n",
    "# Full preprocessing pipeline\n",
    "def preprocess_pipeline(image):\n",
    "    try:\n",
    "        grayscale_image = rgb2gray(image)\n",
    "        print(f\"Grayscale Image Min: {grayscale_image.min()}, Max: {grayscale_image.max()}\")\n",
    "\n",
    "        adf_filtered_image = anisotropic_diffusion_filter(grayscale_image)\n",
    "        print(f\"ADF Filtered Min: {adf_filtered_image.min()}, Max: {adf_filtered_image.max()}\")\n",
    "\n",
    "        skull_stripped_image = skull_stripping(adf_filtered_image)\n",
    "        print(f\"Skull Stripped Min: {skull_stripped_image.min()}, Max: {skull_stripped_image.max()}\")\n",
    "\n",
    "        tophat_image = top_hat_filtering(skull_stripped_image)\n",
    "        print(f\"Tophat Filtered Min: {tophat_image.min()}, Max: {tophat_image.max()}\")\n",
    "\n",
    "        contrasted_image = contrast_enhancement(tophat_image)\n",
    "        print(f\"Contrast Enhanced Min: {contrasted_image.min()}, Max: {contrasted_image.max()}\")\n",
    "\n",
    "        binary_image, _ = get_binary(contrasted_image, thresh=230)\n",
    "        print(f\"Binary Image Min: {binary_image.min()}, Max: {binary_image.max()}\")\n",
    "\n",
    "        segmented_image, _ = watershed_segmentation(binary_image, morphology.disk(10))\n",
    "        print(f\"Segmented Image Min: {segmented_image.min()}, Max: {segmented_image.max()}\")\n",
    "\n",
    "        closed_image_post, opened_image_post = apply_morphological_operations(segmented_image)\n",
    "        print(f\"Opened Image Post Min: {opened_image_post.min()}, Max: {opened_image_post.max()}\")\n",
    "\n",
    "        # Resize to 256x256\n",
    "        resized_opened_image = transform.resize(opened_image_post, (256, 256))\n",
    "        resized_opened_image = (resized_opened_image * 255).astype(np.uint8)\n",
    "        print(f\"Resized Opened Image Min: {resized_opened_image.min()}, Max: {resized_opened_image.max()}\")\n",
    "\n",
    "        # Flatten and scale\n",
    "        flattened_image = resized_opened_image.flatten().reshape(1, -1)\n",
    "        scaler = MinMaxScaler()\n",
    "        scaled_features = scaler.fit_transform(flattened_image)\n",
    "\n",
    "        return scaled_features, resized_opened_image\n",
    "    except Exception as e:\n",
    "        print(f\"Error in preprocessing pipeline: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "# Classification Function\n",
    "def classify_image(image, model_name):\n",
    "    try:\n",
    "        scaled_features, opened_image = preprocess_pipeline(image)\n",
    "        model = loaded_models[model_name]\n",
    "\n",
    "        # Dynamically match feature size\n",
    "        expected_size = model.n_features_in_\n",
    "        if scaled_features.shape[1] != expected_size:\n",
    "            print(f\"Resizing from {scaled_features.shape[1]} to {expected_size}\")\n",
    "            scaled_features = np.resize(scaled_features, (1, expected_size))\n",
    "\n",
    "        prediction = model.predict(scaled_features)\n",
    "        return opened_image, f\"Predicted Label: {prediction[0]}\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error in classification: {e}\")\n",
    "        return None, \"Error\"\n",
    "\n",
    "# Preprocessing Button Function\n",
    "def preprocess_image(image):\n",
    "    _, processed_image = preprocess_pipeline(image)\n",
    "    return processed_image\n",
    "\n",
    "# GUI\n",
    "def gui():\n",
    "    with gr.Blocks() as demo:\n",
    "        gr.Markdown(\"## Image Classification Demo\")\n",
    "\n",
    "        with gr.Row():\n",
    "            with gr.Column():\n",
    "                image_input = gr.Image(label=\"Upload a Photo\", type=\"numpy\")\n",
    "                preprocess_button = gr.Button(\"Preprocess\")\n",
    "                preprocess_output = gr.Image(label=\"Preprocessed Image Preview\")\n",
    "            with gr.Column():\n",
    "                model_dropdown = gr.Dropdown(choices=list(models.keys()), label=\"Select Model\", value=\"Random Forest\")\n",
    "                classify_button = gr.Button(\"Classify\")\n",
    "                prediction_output = gr.Textbox(label=\"Predicted Label\", interactive=False)\n",
    "\n",
    "        preprocess_button.click(preprocess_image, inputs=image_input, outputs=preprocess_output)\n",
    "        classify_button.click(classify_image, inputs=[image_input, model_dropdown], outputs=[preprocess_output, prediction_output])\n",
    "\n",
    "    demo.launch()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    gui()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing pipeline loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# Define the missing class before loading the pickle file\n",
    "class ImagePreprocessor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self  # No training needed\n",
    "\n",
    "    def transform(self, X):\n",
    "        processed_images = []\n",
    "        for image in X:\n",
    "            try:\n",
    "                # Apply the full pipeline to each image\n",
    "                adf_filtered_image = anisotropic_diffusion_filter(image)\n",
    "                skull_stripped_image = skull_stripping(adf_filtered_image)\n",
    "                tophat_image = top_hat_filtering(skull_stripped_image)\n",
    "                contrasted_image = contrast_enhancement(tophat_image)\n",
    "                binary_image, _ = get_binary(contrasted_image, thresh=230)\n",
    "                segmented_image, _ = watershed_segmentation(binary_image, morphology.disk(10))\n",
    "                _, opened_image = apply_morphological_operations(segmented_image)\n",
    "\n",
    "                # Resize to 256x256\n",
    "                resized_opened_image = transform.resize(opened_image, (256, 256), anti_aliasing=True)\n",
    "                if resized_opened_image.max() > 0:\n",
    "                    resized_opened_image = (resized_opened_image / resized_opened_image.max()) * 255\n",
    "                resized_opened_image = resized_opened_image.astype(np.uint8)\n",
    "\n",
    "                # Flatten the image\n",
    "                flattened_image = resized_opened_image.flatten().reshape(1, -1)\n",
    "                \n",
    "                processed_images.append(flattened_image)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing image: {e}\")\n",
    "                processed_images.append(None)\n",
    "\n",
    "        return np.vstack(processed_images)  # Stack all images together\n",
    "\n",
    "# ✅ Now Load the Preprocessing Pipeline\n",
    "import joblib\n",
    "preprocessor = joblib.load(r\"C:\\Marwan APU\\Sem-2\\PR\\brine\\new_pkl\\preprocessing_pipeline.pkl\")\n",
    "print(\"Preprocessing pipeline loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can't get attribute 'ImagePreprocessor' on <module '__main__'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Load preprocessing pipeline\u001b[39;00m\n\u001b[0;32m      8\u001b[0m preprocessing_pipeline_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mMarwan APU\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mSem-2\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mPR\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mbrine\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mnew_pkl\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mpreprocessing_pipeline.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 9\u001b[0m preprocessor \u001b[38;5;241m=\u001b[39m joblib\u001b[38;5;241m.\u001b[39mload(preprocessing_pipeline_path)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Load trained models\u001b[39;00m\n\u001b[0;32m     12\u001b[0m models \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRandom Forest\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mMarwan APU\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mSem-2\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mPR\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mbrine\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mnew_pkl\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mbest_random_forest_model.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKNN\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mMarwan APU\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mSem-2\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mPR\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mbrine\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mnew_pkl\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mbest_KNN_model.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSVM\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mMarwan APU\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mSem-2\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mPR\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mbrine\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mnew_pkl\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124msvm_model.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     19\u001b[0m }\n",
      "File \u001b[1;32mc:\\Users\\Marwan Shamsan\\anaconda3\\Lib\\site-packages\\joblib\\numpy_pickle.py:658\u001b[0m, in \u001b[0;36mload\u001b[1;34m(filename, mmap_mode)\u001b[0m\n\u001b[0;32m    652\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fobj, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    653\u001b[0m                 \u001b[38;5;66;03m# if the returned file object is a string, this means we\u001b[39;00m\n\u001b[0;32m    654\u001b[0m                 \u001b[38;5;66;03m# try to load a pickle file generated with an version of\u001b[39;00m\n\u001b[0;32m    655\u001b[0m                 \u001b[38;5;66;03m# Joblib so we load it with joblib compatibility function.\u001b[39;00m\n\u001b[0;32m    656\u001b[0m                 \u001b[38;5;28;01mreturn\u001b[39;00m load_compatibility(fobj)\n\u001b[1;32m--> 658\u001b[0m             obj \u001b[38;5;241m=\u001b[39m _unpickle(fobj, filename, mmap_mode)\n\u001b[0;32m    659\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "File \u001b[1;32mc:\\Users\\Marwan Shamsan\\anaconda3\\Lib\\site-packages\\joblib\\numpy_pickle.py:577\u001b[0m, in \u001b[0;36m_unpickle\u001b[1;34m(fobj, filename, mmap_mode)\u001b[0m\n\u001b[0;32m    575\u001b[0m obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    576\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 577\u001b[0m     obj \u001b[38;5;241m=\u001b[39m unpickler\u001b[38;5;241m.\u001b[39mload()\n\u001b[0;32m    578\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m unpickler\u001b[38;5;241m.\u001b[39mcompat_mode:\n\u001b[0;32m    579\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe file \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m has been generated with a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    580\u001b[0m                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjoblib version less than 0.10. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    581\u001b[0m                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease regenerate this pickle file.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    582\u001b[0m                       \u001b[38;5;241m%\u001b[39m filename,\n\u001b[0;32m    583\u001b[0m                       \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Marwan Shamsan\\anaconda3\\Lib\\pickle.py:1213\u001b[0m, in \u001b[0;36m_Unpickler.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1211\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEOFError\u001b[39;00m\n\u001b[0;32m   1212\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, bytes_types)\n\u001b[1;32m-> 1213\u001b[0m         dispatch[key[\u001b[38;5;241m0\u001b[39m]](\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m   1214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _Stop \u001b[38;5;28;01mas\u001b[39;00m stopinst:\n\u001b[0;32m   1215\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m stopinst\u001b[38;5;241m.\u001b[39mvalue\n",
      "File \u001b[1;32mc:\\Users\\Marwan Shamsan\\anaconda3\\Lib\\pickle.py:1538\u001b[0m, in \u001b[0;36m_Unpickler.load_stack_global\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(name) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mstr\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(module) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m   1537\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m UnpicklingError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSTACK_GLOBAL requires str\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1538\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfind_class(module, name))\n",
      "File \u001b[1;32mc:\\Users\\Marwan Shamsan\\anaconda3\\Lib\\pickle.py:1582\u001b[0m, in \u001b[0;36m_Unpickler.find_class\u001b[1;34m(self, module, name)\u001b[0m\n\u001b[0;32m   1580\u001b[0m \u001b[38;5;28m__import__\u001b[39m(module, level\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m   1581\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproto \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m:\n\u001b[1;32m-> 1582\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _getattribute(sys\u001b[38;5;241m.\u001b[39mmodules[module], name)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1583\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1584\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(sys\u001b[38;5;241m.\u001b[39mmodules[module], name)\n",
      "File \u001b[1;32mc:\\Users\\Marwan Shamsan\\anaconda3\\Lib\\pickle.py:331\u001b[0m, in \u001b[0;36m_getattribute\u001b[1;34m(obj, name)\u001b[0m\n\u001b[0;32m    329\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(obj, subpath)\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[1;32m--> 331\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt get attribute \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m on \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    332\u001b[0m                              \u001b[38;5;241m.\u001b[39mformat(name, obj)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, parent\n",
      "\u001b[1;31mAttributeError\u001b[0m: Can't get attribute 'ImagePreprocessor' on <module '__main__'>"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import numpy as np\n",
    "import joblib\n",
    "from joblib import load\n",
    "from skimage.color import rgb2gray\n",
    "\n",
    "# Load preprocessing pipeline\n",
    "preprocessing_pipeline_path = r\"C:\\Marwan APU\\Sem-2\\PR\\brine\\new_pkl\\preprocessing_pipeline.pkl\"\n",
    "preprocessor = joblib.load(preprocessing_pipeline_path)\n",
    "\n",
    "# Load trained models\n",
    "models = {\n",
    "    \"Random Forest\": r\"C:\\Marwan APU\\Sem-2\\PR\\brine\\new_pkl\\best_random_forest_model.pkl\",\n",
    "    \"KNN\": r\"C:\\Marwan APU\\Sem-2\\PR\\brine\\new_pkl\\best_KNN_model.pkl\",\n",
    "    \"Decision Tree\": r\"C:\\Marwan APU\\Sem-2\\PR\\brine\\new_pkl\\Decision_tree_model.pkl\",\n",
    "    \"Gaussian NB\": r\"C:\\Marwan APU\\Sem-2\\PR\\brine\\new_pkl\\GaussianNB_model.pkl\",\n",
    "    \"Logistic Regression\": r\"C:\\Marwan APU\\Sem-2\\PR\\brine\\new_pkl\\logistic_regression_model.pkl\",\n",
    "    \"SVM\": r\"C:\\Marwan APU\\Sem-2\\PR\\brine\\new_pkl\\svm_model.pkl\",\n",
    "}\n",
    "\n",
    "loaded_models = {model_name: load(model_path) for model_name, model_path in models.items()}\n",
    "\n",
    "# ✅ Function to dynamically resize an image for visualization\n",
    "def resize_for_visualization(flattened_array, target_size=(256, 256)):\n",
    "    \"\"\"Resizes the flattened array to the target size for visualization.\"\"\"\n",
    "    reshaped_array = flattened_array[: np.prod(target_size)].reshape(target_size)  # Crop and reshape\n",
    "    reshaped_array = (reshaped_array - reshaped_array.min()) / (reshaped_array.max() - reshaped_array.min())  # Normalize\n",
    "    reshaped_array = (reshaped_array * 255).astype(np.uint8)  # Convert to 8-bit image\n",
    "    return reshaped_array\n",
    "\n",
    "# ✅ Function to preprocess image using the saved pipeline\n",
    "def preprocess_image(image):\n",
    "    try:\n",
    "        grayscale_image = rgb2gray(image)  # Convert to grayscale if needed\n",
    "        processed_features = preprocessor.transform([grayscale_image])  # Apply the saved pipeline\n",
    "        visualization_image = resize_for_visualization(processed_features.flatten())  # Resize for preview\n",
    "        return image, visualization_image\n",
    "    except Exception as e:\n",
    "        print(f\"Error in preprocessing: {e}\")\n",
    "        return image, None\n",
    "\n",
    "# Define label mapping for predictions\n",
    "label_mapping = {\n",
    "    0: \"Tumor Detected\",         # Class 0 -> Healthy\n",
    "    1: \"Healthy\",  # Class 1 -> Tumor Detected2: \"Cancer Detected\"  # (Optional) Example for a third class\n",
    "}\n",
    "\n",
    "# ✅ Classification Function Using Preprocessed Image\n",
    "def classify_image(image, model_name):\n",
    "    try:\n",
    "        grayscale_image = rgb2gray(image)  # Ensure grayscale conversion\n",
    "        processed_features = preprocessor.transform([grayscale_image])  # Apply preprocessing\n",
    "\n",
    "        if processed_features is None:\n",
    "            return image, None, \"Error in preprocessing\"\n",
    "\n",
    "        model = loaded_models[model_name]\n",
    "\n",
    "        # Ensure feature size matches model expectations\n",
    "        expected_size = model.n_features_in_\n",
    "        flattened_features = processed_features.flatten().reshape(1, -1)  # Flatten before resizing\n",
    "        if flattened_features.shape[1] != expected_size:\n",
    "            flattened_features = np.resize(flattened_features, (1, expected_size))\n",
    "\n",
    "        # Get the numerical prediction\n",
    "        prediction = model.predict(flattened_features)[0]  # Single prediction\n",
    "\n",
    "        # Map the numerical label to a meaningful description\n",
    "        label = label_mapping.get(prediction, \"Unknown\")  # Fallback to \"Unknown\" if label is missing\n",
    "\n",
    "        # Resize for visualization\n",
    "        visualization_image = resize_for_visualization(processed_features.flatten())  # Resize for preview\n",
    "        return image, visualization_image, f\"Result: {label}\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error in classification: {e}\")\n",
    "        return image, None, \"Error\"\n",
    "\n",
    "\n",
    "# ✅ Gradio GUI\n",
    "def gui():\n",
    "    with gr.Blocks() as demo:\n",
    "        gr.Markdown(\"## Image Classification Demo\")\n",
    "\n",
    "        with gr.Row():\n",
    "            with gr.Column():\n",
    "                image_input = gr.Image(label=\"Upload a Photo\", type=\"numpy\", interactive=True)\n",
    "                preprocess_button = gr.Button(\"Preprocess\")\n",
    "                preprocess_output = gr.Image(label=\"Preprocessed Image Preview\")\n",
    "            with gr.Column():\n",
    "                model_dropdown = gr.Dropdown(choices=list(models.keys()), label=\"Select Model\", value=\"Random Forest\")\n",
    "                classify_button = gr.Button(\"Classify\")\n",
    "                prediction_output = gr.Textbox(label=\"Predicted Label\", interactive=False)\n",
    "\n",
    "        # Button actions\n",
    "        preprocess_button.click(preprocess_image, inputs=image_input, outputs=[image_input, preprocess_output])\n",
    "        classify_button.click(classify_image, inputs=[image_input, model_dropdown], outputs=[image_input, preprocess_output, prediction_output])\n",
    "\n",
    "    demo.launch()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    gui()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell 1 executed: All imports, models, and preprocessing functions are loaded.\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Imports, model loading, and pipeline functions\n",
    "\n",
    "import gradio as gr\n",
    "import numpy as np\n",
    "import cupy as cp\n",
    "import cv2\n",
    "from skimage.util import img_as_ubyte, img_as_float\n",
    "from skimage import morphology, filters, segmentation, exposure, feature, transform\n",
    "from scipy.ndimage import convolve, gaussian_gradient_magnitude, distance_transform_edt\n",
    "from scipy.ndimage import label as nd_label\n",
    "from skimage.color import rgb2gray\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from joblib import load\n",
    "\n",
    "# ---------------------------\n",
    "# Load trained models\n",
    "# ---------------------------\n",
    "models = {\n",
    "    \"Random Forest\": r\"C:\\Marwan APU\\Sem-2\\PR\\brine\\new_pkl\\best_random_forest_model.pkl\",\n",
    "    \"KNN\": r\"C:\\Marwan APU\\Sem-2\\PR\\brine\\new_pkl\\best_KNN_model.pkl\",\n",
    "    \"Decision Tree\": r\"C:\\Marwan APU\\Sem-2\\PR\\brine\\new_pkl\\Decision_tree_model.pkl\",\n",
    "    \"Gaussian NB\": r\"C:\\Marwan APU\\Sem-2\\PR\\brine\\new_pkl\\GaussianNB_model.pkl\",\n",
    "    \"Logistic Regression\": r\"C:\\Marwan APU\\Sem-2\\PR\\brine\\new_pkl\\logistic_regression_model.pkl\",\n",
    "    \"SVM\": r\"C:\\Marwan APU\\Sem-2\\PR\\brine\\new_pkl\\svm_model.pkl\",\n",
    "}\n",
    "loaded_models = {model_name: load(model_path) for model_name, model_path in models.items()}\n",
    "\n",
    "# ---------------------------\n",
    "# Preprocessing Pipeline Functions\n",
    "# ---------------------------\n",
    "def anisotropic_diffusion_filter(image, alpha=0.1, beta=0.1, iterations=3):\n",
    "    image = img_as_float(image.copy())\n",
    "    for _ in range(iterations):\n",
    "        gradient_magnitude = gaussian_gradient_magnitude(image, sigma=1)\n",
    "        c = 1.0 / (1.0 + (gradient_magnitude / beta) ** 2)\n",
    "        diff_north = convolve(image, np.array([[0, 1, 0], [0, -1, 0], [0, 0, 0]]))\n",
    "        diff_south = convolve(image, np.array([[0, 0, 0], [0, -1, 0], [0, 1, 0]]))\n",
    "        diff_east = convolve(image, np.array([[0, 0, 0], [0, -1, 1], [0, 0, 0]]))\n",
    "        diff_west = convolve(image, np.array([[0, 0, 0], [1, -1, 0], [0, 0, 0]]))\n",
    "        image += alpha * (c * diff_north + c * diff_south + c * diff_east + c * diff_west)\n",
    "    return img_as_ubyte(image)\n",
    "\n",
    "def skull_stripping(image, se_closing=None, se_erosion=None, skull_remove_area=2000):\n",
    "    if se_closing is None:\n",
    "        se_closing = morphology.disk(15)\n",
    "    if se_erosion is None:\n",
    "        se_erosion = morphology.disk(30)\n",
    "    threshold_value = filters.threshold_otsu(image)\n",
    "    binary_image = image > threshold_value\n",
    "    filled_image = morphology.closing(binary_image, se_closing)\n",
    "    filled_image = morphology.remove_small_holes(filled_image, area_threshold=skull_remove_area)\n",
    "    eroded_image = morphology.erosion(filled_image, se_erosion)\n",
    "    return np.where(eroded_image, image, 0)\n",
    "\n",
    "def top_hat_filtering(image, disk_size=30):\n",
    "    footprint = morphology.disk(disk_size)\n",
    "    return morphology.white_tophat(image, footprint)\n",
    "\n",
    "def contrast_enhancement(image):\n",
    "    contrasted_image = exposure.equalize_hist(image)\n",
    "    contrasted_image = (contrasted_image - np.min(contrasted_image)) / (np.max(contrasted_image) - np.min(contrasted_image))\n",
    "    return img_as_ubyte(contrasted_image)\n",
    "\n",
    "def get_binary(image, thresh=None):\n",
    "    if thresh is None:\n",
    "        thresh = filters.threshold_otsu(image)\n",
    "    binary_image = image > thresh\n",
    "    return binary_image, thresh\n",
    "\n",
    "def watershed_segmentation(image, se_peak_local=np.ones((3, 3))):\n",
    "    distance = distance_transform_edt(image)\n",
    "    local_maxi = feature.peak_local_max(distance, labels=image, footprint=se_peak_local, exclude_border=False)\n",
    "    local_maxi_mask = np.zeros_like(image, dtype=bool)\n",
    "    local_maxi_mask[tuple(local_maxi.T)] = True\n",
    "    markers = nd_label(local_maxi_mask)[0]\n",
    "    segmented_image = segmentation.watershed(-distance, markers, mask=image)\n",
    "    nbr_labels = np.max(segmented_image)\n",
    "    return segmented_image, nbr_labels\n",
    "\n",
    "def apply_morphological_operations(segmented_image):\n",
    "    if not isinstance(segmented_image, np.ndarray) or segmented_image.ndim != 2:\n",
    "        return None, None\n",
    "    closed_image = morphology.closing(segmented_image, morphology.disk(6))\n",
    "    opened_image = morphology.opening(closed_image, morphology.disk(5))\n",
    "    return closed_image, opened_image\n",
    "\n",
    "def preprocess_pipeline(image):\n",
    "    try:\n",
    "        # Convert to grayscale\n",
    "        grayscale_image = rgb2gray(image)\n",
    "        print(f\"Grayscale Image Min: {grayscale_image.min()}, Max: {grayscale_image.max()}\")\n",
    "\n",
    "        adf_filtered_image = anisotropic_diffusion_filter(grayscale_image)\n",
    "        print(f\"ADF Filtered Min: {adf_filtered_image.min()}, Max: {adf_filtered_image.max()}\")\n",
    "\n",
    "        skull_stripped_image = skull_stripping(adf_filtered_image)\n",
    "        print(f\"Skull Stripped Min: {skull_stripped_image.min()}, Max: {skull_stripped_image.max()}\")\n",
    "\n",
    "        tophat_image = top_hat_filtering(skull_stripped_image)\n",
    "        print(f\"Tophat Filtered Min: {tophat_image.min()}, Max: {tophat_image.max()}\")\n",
    "\n",
    "        contrasted_image = contrast_enhancement(tophat_image)\n",
    "        print(f\"Contrast Enhanced Min: {contrasted_image.min()}, Max: {contrasted_image.max()}\")\n",
    "\n",
    "        # Here thresh is set to 230 (assumes an 8-bit image after contrast enhancement)\n",
    "        binary_image, _ = get_binary(contrasted_image, thresh=230)\n",
    "        print(f\"Binary Image Min: {binary_image.min()}, Max: {binary_image.max()}\")\n",
    "\n",
    "        segmented_image, _ = watershed_segmentation(binary_image, morphology.disk(10))\n",
    "        print(f\"Segmented Image Min: {segmented_image.min()}, Max: {segmented_image.max()}\")\n",
    "\n",
    "        closed_image_post, opened_image_post = apply_morphological_operations(segmented_image)\n",
    "        print(f\"Opened Image Post Min: {opened_image_post.min()}, Max: {opened_image_post.max()}\")\n",
    "\n",
    "        # Resize to 256x256 for further processing/visualization\n",
    "        resized_opened_image = transform.resize(opened_image_post, (256, 256), anti_aliasing=True)\n",
    "        resized_opened_image = (resized_opened_image * 255).astype(np.uint8)\n",
    "        print(f\"Resized Opened Image Min: {resized_opened_image.min()}, Max: {resized_opened_image.max()}\")\n",
    "\n",
    "        # Flatten and scale features\n",
    "        flattened_image = resized_opened_image.flatten().reshape(1, -1)\n",
    "        from sklearn.preprocessing import MinMaxScaler  # (re-import if needed)\n",
    "        scaler = MinMaxScaler()\n",
    "        scaled_features = scaler.fit_transform(flattened_image)\n",
    "\n",
    "        return scaled_features, resized_opened_image\n",
    "    except Exception as e:\n",
    "        print(f\"Error in preprocessing pipeline: {e}\")\n",
    "        raise\n",
    "\n",
    "# Additional helper functions for GUI (used later)\n",
    "def preprocess_image(image):\n",
    "    \"\"\"Helper function for the GUI Preprocess button.\"\"\"\n",
    "    _, processed_image = preprocess_pipeline(image)\n",
    "    return processed_image\n",
    "\n",
    "def classify_image(image, model_name):\n",
    "    try:\n",
    "        scaled_features, opened_image = preprocess_pipeline(image)\n",
    "        model = loaded_models[model_name]\n",
    "        # Adjust feature size if necessary\n",
    "        expected_size = model.n_features_in_\n",
    "        if scaled_features.shape[1] != expected_size:\n",
    "            print(f\"Resizing from {scaled_features.shape[1]} to {expected_size}\")\n",
    "            scaled_features = np.resize(scaled_features, (1, expected_size))\n",
    "        prediction = model.predict(scaled_features)\n",
    "        return opened_image, f\"Predicted Label: {prediction[0]}\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error in classification: {e}\")\n",
    "        return None, \"Error\"\n",
    "\n",
    "print(\"Cell 1 executed: All imports, models, and preprocessing functions are loaded.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell 2 executed: Preprocessing pipeline loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Define ImagePreprocessor class and load the preprocessing pipeline\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import joblib  # Ensure joblib is imported\n",
    "\n",
    "class ImagePreprocessor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass  # No initialization parameters needed\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self  # No fitting needed\n",
    "\n",
    "    def transform(self, X):\n",
    "        processed_images = []\n",
    "        for image in X:\n",
    "            try:\n",
    "                # Apply the same pipeline as defined above\n",
    "                adf_filtered_image = anisotropic_diffusion_filter(image)\n",
    "                skull_stripped_image = skull_stripping(adf_filtered_image)\n",
    "                tophat_image = top_hat_filtering(skull_stripped_image)\n",
    "                contrasted_image = contrast_enhancement(tophat_image)\n",
    "                binary_image, _ = get_binary(contrasted_image, thresh=230)\n",
    "                segmented_image, _ = watershed_segmentation(binary_image, morphology.disk(10))\n",
    "                _, opened_image = apply_morphological_operations(segmented_image)\n",
    "                # Resize to 256x256 for consistency\n",
    "                resized_opened_image = transform.resize(opened_image, (256, 256), anti_aliasing=True)\n",
    "                if resized_opened_image.max() > 0:\n",
    "                    resized_opened_image = (resized_opened_image / resized_opened_image.max()) * 255\n",
    "                resized_opened_image = resized_opened_image.astype(np.uint8)\n",
    "                flattened_image = resized_opened_image.flatten().reshape(1, -1)\n",
    "                processed_images.append(flattened_image)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing image: {e}\")\n",
    "                processed_images.append(None)\n",
    "        return np.vstack(processed_images)\n",
    "\n",
    "# ---------------------------\n",
    "# Load the preprocessing pipeline from disk\n",
    "# ---------------------------\n",
    "preprocessing_pipeline_path = r\"C:\\Marwan APU\\Sem-2\\PR\\brine\\new_pkl\\preprocessing_pipeline.pkl\"\n",
    "preprocessor = joblib.load(preprocessing_pipeline_path)\n",
    "print(\"Cell 2 executed: Preprocessing pipeline loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7863\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in callback _ProactorBasePipeTransport._call_connection_lost(None)\n",
      "handle: <Handle _ProactorBasePipeTransport._call_connection_lost(None)>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Marwan Shamsan\\anaconda3\\Lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\Users\\Marwan Shamsan\\anaconda3\\Lib\\asyncio\\proactor_events.py\", line 165, in _call_connection_lost\n",
      "    self._sock.shutdown(socket.SHUT_RDWR)\n",
      "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Gradio GUI Launch\n",
    "\n",
    "import gradio as gr\n",
    "import numpy as np\n",
    "import joblib\n",
    "from skimage.color import rgb2gray\n",
    "\n",
    "# --- Helper function for visualization ---\n",
    "def resize_for_visualization(flattened_array, target_size=(256, 256)):\n",
    "    \"\"\"Resizes a flattened array back to a 2D image for visualization.\"\"\"\n",
    "    reshaped_array = flattened_array[: np.prod(target_size)].reshape(target_size)\n",
    "    # Normalize to [0, 255]\n",
    "    reshaped_array = (reshaped_array - reshaped_array.min()) / (reshaped_array.max() - reshaped_array.min() + 1e-8)\n",
    "    reshaped_array = (reshaped_array * 255).astype(np.uint8)\n",
    "    return reshaped_array\n",
    "\n",
    "# --- Redefine functions that use the preprocessor (if needed) ---\n",
    "def preprocess_image_gui(image):\n",
    "    \"\"\"\n",
    "    Uses the saved preprocessor to transform the image and then \n",
    "    resizes the output for visualization.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        grayscale_image = rgb2gray(image)\n",
    "        processed_features = preprocessor.transform([grayscale_image])\n",
    "        visualization_image = resize_for_visualization(processed_features.flatten())\n",
    "        return image, visualization_image\n",
    "    except Exception as e:\n",
    "        print(f\"Error in preprocessing (GUI): {e}\")\n",
    "        return image, None\n",
    "\n",
    "def classify_image_gui(image, model_name):\n",
    "    \"\"\"\n",
    "    Applies the saved preprocessor and then uses the selected model for classification.\n",
    "    Also resizes the processed features for preview.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        grayscale_image = rgb2gray(image)\n",
    "        processed_features = preprocessor.transform([grayscale_image])\n",
    "        if processed_features is None:\n",
    "            return image, None, \"Error in preprocessing\"\n",
    "        model = loaded_models[model_name]\n",
    "        # Resize features if needed\n",
    "        expected_size = model.n_features_in_\n",
    "        flattened_features = processed_features.flatten().reshape(1, -1)\n",
    "        if flattened_features.shape[1] != expected_size:\n",
    "            flattened_features = np.resize(flattened_features, (1, expected_size))\n",
    "        prediction = model.predict(flattened_features)[0]\n",
    "        # Map prediction to a label (adjust mapping as needed)\n",
    "        label_mapping = {0: \"Tumor Detected\", 1: \"Healthy\"}\n",
    "        label = label_mapping.get(prediction, \"Unknown\")\n",
    "        visualization_image = resize_for_visualization(processed_features.flatten())\n",
    "        return image, visualization_image, f\"Result: {label}\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error in classification (GUI): {e}\")\n",
    "        return image, None, \"Error\"\n",
    "\n",
    "# --- Gradio Interface ---\n",
    "def gui():\n",
    "    with gr.Blocks() as demo:\n",
    "        gr.Markdown(\"## Image Classification Demo\")\n",
    "        with gr.Row():\n",
    "            with gr.Column():\n",
    "                image_input = gr.Image(label=\"Upload a Photo\", type=\"numpy\", interactive=True)\n",
    "                preprocess_button = gr.Button(\"Preprocess\")\n",
    "                preprocess_output = gr.Image(label=\"Preprocessed Image Preview\")\n",
    "            with gr.Column():\n",
    "                model_dropdown = gr.Dropdown(choices=list(models.keys()), label=\"Select Model\", value=\"Random Forest\")\n",
    "                classify_button = gr.Button(\"Classify\")\n",
    "                prediction_output = gr.Textbox(label=\"Predicted Label\", interactive=False)\n",
    "        \n",
    "        # When the Preprocess button is clicked:\n",
    "        preprocess_button.click(\n",
    "            preprocess_image_gui, \n",
    "            inputs=image_input, \n",
    "            outputs=[image_input, preprocess_output]\n",
    "        )\n",
    "        # When the Classify button is clicked:\n",
    "        classify_button.click(\n",
    "            classify_image_gui, \n",
    "            inputs=[image_input, model_dropdown], \n",
    "            outputs=[image_input, preprocess_output, prediction_output]\n",
    "        )\n",
    "    demo.launch()\n",
    "\n",
    "gui()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
